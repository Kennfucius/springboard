{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 1: Recommender System In-Depth Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kenneth Liao\n",
    "\n",
    "Original datasource: https://datahack.analyticsvidhya.com/contest/practice-problem-recommendation-engine/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import minimize, fmin_cg\n",
    "\n",
    "# enable offline plotting in plotly\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our 3 datasets\n",
    "users = pd.read_csv('data/user_features.csv')\n",
    "problems =  pd.read_csv('data/problem_features.csv')\n",
    "submissions = pd.read_csv('data/train_submissions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background & Problem Statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, our goal is to recommend practice problems to users given some information about the problems they have already solved. There are many criteria we could choose to base how we recommend problems. For the purpose of this model, I will keep the criteria simple. The criteria are as follows:\n",
    "\n",
    "1. The problem has not yet been attempted by the user.\n",
    "2. The predicted number of attempts the user will require to solve the problem is equal to 2 or 3.\n",
    "\n",
    "Given the criteria defined above, we must first be able to predict how many attempts a user will require to solve a problem they've never attempted before. I will perform this prediction using two very different models. \n",
    "\n",
    "The first model will be a Random Forest Classifier. For this model, I will use meta data available for users and problems. The goal is to find patterns in the user and problem features that predict well the number of attempts for a given user-problem combination.\n",
    "\n",
    "The second model will be a collaborative filtering model. This model will employ stochastic gradient descent (SGD) to find an approximate solution to the single value decomposition (SVD) of our user-problem matrix. In this case, we will not use any user or problem features. Predictions will be made exclusively using the history of users and problems solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the submissions dataset. This dataset has 3 columns: user_id, problem_id, and attempts_range. Attempts_range gives the range of attempts that the user_id took to solve the problem_id and is defined in the original datasource as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>attempts_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_232</td>\n",
       "      <td>prob_6507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_3568</td>\n",
       "      <td>prob_2994</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_1600</td>\n",
       "      <td>prob_5071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_2256</td>\n",
       "      <td>prob_703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_2321</td>\n",
       "      <td>prob_356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id problem_id  attempts_range\n",
       "0   user_232  prob_6507               1\n",
       "1  user_3568  prob_2994               3\n",
       "2  user_1600  prob_5071               1\n",
       "3  user_2256   prob_703               1\n",
       "4  user_2321   prob_356               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We have used following criteria to define the attempts_range :-\n",
    ">\n",
    ">            attempts_range            No. of attempts lies inside\n",
    ">\n",
    ">            1                                         1-1\n",
    ">\n",
    ">            2                                         2-3\n",
    ">\n",
    ">            3                                         4-5\n",
    ">\n",
    ">            4                                         6-7\n",
    ">\n",
    ">            5                                         8-9\n",
    ">\n",
    ">            6                                         >=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do to prepare the data for the random forest model is convert categorical, string columns into dummy variables. We do this for both the user and problem features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>submission_count</th>\n",
       "      <th>problem_solved</th>\n",
       "      <th>contribution</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>last_online_time_seconds</th>\n",
       "      <th>max_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>registration_time_seconds</th>\n",
       "      <th>user_attempts_median</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Ukraine</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States</th>\n",
       "      <th>country_Uzbekistan</th>\n",
       "      <th>country_Venezuela</th>\n",
       "      <th>country_Vietnam</th>\n",
       "      <th>rank_advanced</th>\n",
       "      <th>rank_beginner</th>\n",
       "      <th>rank_expert</th>\n",
       "      <th>rank_intermediate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>84</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1505162220</td>\n",
       "      <td>502.007</td>\n",
       "      <td>499.713</td>\n",
       "      <td>1469108674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_10</td>\n",
       "      <td>246</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1505079658</td>\n",
       "      <td>326.548</td>\n",
       "      <td>313.360</td>\n",
       "      <td>1472038187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_100</td>\n",
       "      <td>642</td>\n",
       "      <td>574</td>\n",
       "      <td>27</td>\n",
       "      <td>106</td>\n",
       "      <td>1505073569</td>\n",
       "      <td>458.429</td>\n",
       "      <td>385.894</td>\n",
       "      <td>1323974332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1000</td>\n",
       "      <td>259</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1505579889</td>\n",
       "      <td>371.273</td>\n",
       "      <td>336.583</td>\n",
       "      <td>1450375392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_1001</td>\n",
       "      <td>554</td>\n",
       "      <td>492</td>\n",
       "      <td>-6</td>\n",
       "      <td>55</td>\n",
       "      <td>1504521879</td>\n",
       "      <td>472.190</td>\n",
       "      <td>450.975</td>\n",
       "      <td>1423399585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  submission_count  problem_solved  contribution  follower_count  \\\n",
       "0     user_1                84              73            10             120   \n",
       "1    user_10               246             211             0              30   \n",
       "2   user_100               642             574            27             106   \n",
       "3  user_1000               259             235             0              41   \n",
       "4  user_1001               554             492            -6              55   \n",
       "\n",
       "   last_online_time_seconds  max_rating   rating  registration_time_seconds  \\\n",
       "0                1505162220     502.007  499.713                 1469108674   \n",
       "1                1505079658     326.548  313.360                 1472038187   \n",
       "2                1505073569     458.429  385.894                 1323974332   \n",
       "3                1505579889     371.273  336.583                 1450375392   \n",
       "4                1504521879     472.190  450.975                 1423399585   \n",
       "\n",
       "   user_attempts_median  ...  country_Ukraine  country_United Kingdom  \\\n",
       "0                   1.0  ...                0                       0   \n",
       "1                   1.0  ...                0                       0   \n",
       "2                   1.0  ...                0                       0   \n",
       "3                   1.0  ...                0                       0   \n",
       "4                   1.0  ...                0                       0   \n",
       "\n",
       "   country_United States  country_Uzbekistan  country_Venezuela  \\\n",
       "0                      0                   0                  0   \n",
       "1                      0                   0                  0   \n",
       "2                      0                   0                  0   \n",
       "3                      0                   0                  0   \n",
       "4                      0                   0                  0   \n",
       "\n",
       "   country_Vietnam  rank_advanced  rank_beginner  rank_expert  \\\n",
       "0                0              1              0            0   \n",
       "1                0              0              0            0   \n",
       "2                0              0              0            0   \n",
       "3                0              0              0            0   \n",
       "4                0              0              0            0   \n",
       "\n",
       "   rank_intermediate  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.get_dummies(users.set_index('user_id')).reset_index()\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>points</th>\n",
       "      <th>problem_attempts_median</th>\n",
       "      <th>problem_attempts_min</th>\n",
       "      <th>problem_attempts_max</th>\n",
       "      <th>problem_attempts_count</th>\n",
       "      <th>problem_attempts_iqr</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>and</th>\n",
       "      <th>binary</th>\n",
       "      <th>...</th>\n",
       "      <th>level_type_E</th>\n",
       "      <th>level_type_F</th>\n",
       "      <th>level_type_G</th>\n",
       "      <th>level_type_H</th>\n",
       "      <th>level_type_I</th>\n",
       "      <th>level_type_J</th>\n",
       "      <th>level_type_K</th>\n",
       "      <th>level_type_L</th>\n",
       "      <th>level_type_M</th>\n",
       "      <th>level_type_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prob_1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prob_10</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prob_100</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prob_1000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prob_1001</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  problem_id  points  problem_attempts_median  problem_attempts_min  \\\n",
       "0     prob_1   500.0                      1.5                   1.0   \n",
       "1    prob_10  4500.0                      6.0                   6.0   \n",
       "2   prob_100  1000.0                      1.0                   1.0   \n",
       "3  prob_1000   500.0                      1.0                   1.0   \n",
       "4  prob_1001  2000.0                      1.0                   1.0   \n",
       "\n",
       "   problem_attempts_max  problem_attempts_count  problem_attempts_iqr  \\\n",
       "0                   2.0                     2.0                 0.005   \n",
       "1                   6.0                     1.0                 0.000   \n",
       "2                   1.0                     1.0                 0.000   \n",
       "3                   6.0                   246.0                 0.000   \n",
       "4                   2.0                    10.0                 0.000   \n",
       "\n",
       "   algorithms  and  binary  ...  level_type_E  level_type_F  level_type_G  \\\n",
       "0           0    0       0  ...             0             0             0   \n",
       "1           0    0       0  ...             0             0             0   \n",
       "2           0    0       0  ...             0             0             0   \n",
       "3           0    0       0  ...             0             0             0   \n",
       "4           0    0       0  ...             0             0             0   \n",
       "\n",
       "   level_type_H  level_type_I  level_type_J  level_type_K  level_type_L  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             1             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   level_type_M  level_type_N  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             0             0  \n",
       "4             0             0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems = pd.get_dummies(problems.set_index('problem_id')).reset_index()\n",
    "problems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by splitting the whole dataset into a train (X_train) and test (X_test) set. I'll further split the X_train data into a smaller training set (R_train) and a cross-validation set (R_cv) for hyperparameter tuning. This split must be done on the original submissions dataset before pivoting the data into a sparse matrix. Once in sparse matrix format, sampling the dataset will also sample the null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, R_test = train_test_split(submissions, test_size=0.25, random_state=42)\n",
    "\n",
    "R_train, R_cv = train_test_split(train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>attempts_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66107</th>\n",
       "      <td>user_2579</td>\n",
       "      <td>prob_5765</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30619</th>\n",
       "      <td>user_2646</td>\n",
       "      <td>prob_4503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73139</th>\n",
       "      <td>user_3160</td>\n",
       "      <td>prob_506</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152423</th>\n",
       "      <td>user_2213</td>\n",
       "      <td>prob_3331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118307</th>\n",
       "      <td>user_3040</td>\n",
       "      <td>prob_617</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id problem_id  attempts_range\n",
       "66107   user_2579  prob_5765               2\n",
       "30619   user_2646  prob_4503               1\n",
       "73139   user_3160   prob_506               4\n",
       "152423  user_2213  prob_3331               1\n",
       "118307  user_3040   prob_617               2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare a single dataframe that joins the user and problem features with the submissions data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>submission_count</th>\n",
       "      <th>problem_solved</th>\n",
       "      <th>contribution</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>last_online_time_seconds</th>\n",
       "      <th>max_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>registration_time_seconds</th>\n",
       "      <th>user_attempts_median</th>\n",
       "      <th>user_attempts_min</th>\n",
       "      <th>...</th>\n",
       "      <th>level_type_E</th>\n",
       "      <th>level_type_F</th>\n",
       "      <th>level_type_G</th>\n",
       "      <th>level_type_H</th>\n",
       "      <th>level_type_I</th>\n",
       "      <th>level_type_J</th>\n",
       "      <th>level_type_K</th>\n",
       "      <th>level_type_L</th>\n",
       "      <th>level_type_M</th>\n",
       "      <th>level_type_N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_2579</th>\n",
       "      <th>prob_5765</th>\n",
       "      <td>676</td>\n",
       "      <td>636</td>\n",
       "      <td>39</td>\n",
       "      <td>90</td>\n",
       "      <td>1505150936</td>\n",
       "      <td>487.959</td>\n",
       "      <td>487.959</td>\n",
       "      <td>1416244222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_3138</th>\n",
       "      <th>prob_5765</th>\n",
       "      <td>1333</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>1505506845</td>\n",
       "      <td>499.140</td>\n",
       "      <td>489.679</td>\n",
       "      <td>1438061830</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1861</th>\n",
       "      <th>prob_5765</th>\n",
       "      <td>498</td>\n",
       "      <td>436</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1505583689</td>\n",
       "      <td>489.679</td>\n",
       "      <td>463.876</td>\n",
       "      <td>1380916526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_262</th>\n",
       "      <th>prob_5765</th>\n",
       "      <td>98</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>1496108464</td>\n",
       "      <td>524.656</td>\n",
       "      <td>519.209</td>\n",
       "      <td>1413513739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_374</th>\n",
       "      <th>prob_5765</th>\n",
       "      <td>150</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1499900942</td>\n",
       "      <td>458.429</td>\n",
       "      <td>458.429</td>\n",
       "      <td>1314604890</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      submission_count  problem_solved  contribution  \\\n",
       "user_id   problem_id                                                   \n",
       "user_2579 prob_5765                676             636            39   \n",
       "user_3138 prob_5765               1333            1280             0   \n",
       "user_1861 prob_5765                498             436             0   \n",
       "user_262  prob_5765                 98              79             3   \n",
       "user_374  prob_5765                150             136             0   \n",
       "\n",
       "                      follower_count  last_online_time_seconds  max_rating  \\\n",
       "user_id   problem_id                                                         \n",
       "user_2579 prob_5765               90                1505150936     487.959   \n",
       "user_3138 prob_5765              114                1505506845     499.140   \n",
       "user_1861 prob_5765               26                1505583689     489.679   \n",
       "user_262  prob_5765               44                1496108464     524.656   \n",
       "user_374  prob_5765               71                1499900942     458.429   \n",
       "\n",
       "                       rating  registration_time_seconds  \\\n",
       "user_id   problem_id                                       \n",
       "user_2579 prob_5765   487.959                 1416244222   \n",
       "user_3138 prob_5765   489.679                 1438061830   \n",
       "user_1861 prob_5765   463.876                 1380916526   \n",
       "user_262  prob_5765   519.209                 1413513739   \n",
       "user_374  prob_5765   458.429                 1314604890   \n",
       "\n",
       "                      user_attempts_median  user_attempts_min  ...  \\\n",
       "user_id   problem_id                                           ...   \n",
       "user_2579 prob_5765                    1.0                1.0  ...   \n",
       "user_3138 prob_5765                    2.0                1.0  ...   \n",
       "user_1861 prob_5765                    1.0                1.0  ...   \n",
       "user_262  prob_5765                    1.0                1.0  ...   \n",
       "user_374  prob_5765                    2.0                1.0  ...   \n",
       "\n",
       "                      level_type_E  level_type_F  level_type_G  level_type_H  \\\n",
       "user_id   problem_id                                                           \n",
       "user_2579 prob_5765              0             0             0             0   \n",
       "user_3138 prob_5765              0             0             0             0   \n",
       "user_1861 prob_5765              0             0             0             0   \n",
       "user_262  prob_5765              0             0             0             0   \n",
       "user_374  prob_5765              0             0             0             0   \n",
       "\n",
       "                      level_type_I  level_type_J  level_type_K  level_type_L  \\\n",
       "user_id   problem_id                                                           \n",
       "user_2579 prob_5765              0             0             0             0   \n",
       "user_3138 prob_5765              0             0             0             0   \n",
       "user_1861 prob_5765              0             0             0             0   \n",
       "user_262  prob_5765              0             0             0             0   \n",
       "user_374  prob_5765              0             0             0             0   \n",
       "\n",
       "                      level_type_M  level_type_N  \n",
       "user_id   problem_id                              \n",
       "user_2579 prob_5765              0             0  \n",
       "user_3138 prob_5765              0             0  \n",
       "user_1861 prob_5765              0             0  \n",
       "user_262  prob_5765              0             0  \n",
       "user_374  prob_5765              0             0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = R_train.merge(users, on='user_id').merge(problems, on='problem_id')\n",
    "X_cv = R_cv.merge(users, on='user_id').merge(problems, on='problem_id')\n",
    "\n",
    "# remove rows with any null values\n",
    "X_train = X_train.loc[:,X_train.notnull().all()]\n",
    "X_cv = X_cv.loc[:,X_cv.notnull().all()]\n",
    "\n",
    "y_train = X_train.set_index(['user_id', 'problem_id'])['attempts_range']\n",
    "X_train = X_train.set_index(['user_id', 'problem_id']).loc[:,'submission_count':]\n",
    "\n",
    "y_cv = X_cv.set_index(['user_id', 'problem_id'])['attempts_range']\n",
    "X_cv = X_cv.set_index(['user_id', 'problem_id']).loc[:,'submission_count':]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    problem_id\n",
       "user_2579  prob_5765     2\n",
       "user_3138  prob_5765     1\n",
       "user_1861  prob_5765     1\n",
       "user_262   prob_5765     1\n",
       "user_374   prob_5765     4\n",
       "Name: attempts_range, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe X now contains all of the user and problem feature data for each combination of user_id and problem_id. Thus, for each training sample or row, we will use the combination of user and problem features to predict the attempts_range. The attempts_range for each user-problem combination is saved in y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplest Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from our previous exploratory analysis of this data that 1 is by far the most common attempts_range. A very simple prediction model we can make is just to predict the most common value for all missing values. Let's see how such a model would do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To benchmark our models, we'll be using sklearn's f1_score function with the average argument set to \"weighted\". This function will compute the f1-score for each of the labels in the dataset and then take a weighted average of the scores depending on how many samples are in each label. Thus, we will simply get one overall f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(Ytrue, Ypred, average='weighted'):\n",
    "    \"\"\"Compute the f1_score between a matrix with actual\n",
    "    values (Ytrue) and a matrix with predictions (Ypred).\n",
    "    Ytrue and Ypred are required to have the same \n",
    "    dimensions.\n",
    "    \"\"\"\n",
    "    # get indices of non-NaN values in Ytrue\n",
    "    mask = ~np.isnan(np.array(Ytrue).flatten(order='C'))\n",
    "    \n",
    "    # flatten matrices to 1D arrays\n",
    "    # use the mask to get only non-NaN values\n",
    "    ytrue = np.array(Ytrue).flatten(order='C')[mask]\n",
    "    ypred = np.array(Ypred).flatten(order='C')[mask]\n",
    "    \n",
    "    return f1_score(ytrue, ypred, average=average, labels=[1.0,2.0,3.0,4.0,5.0,6.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for predicting all ones on training data: 0.3708\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.ones(len(y_train))\n",
    "\n",
    "print('F1 score for predicting all ones on training data: %s' % round(f1(y_train, y_pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score we got for predicting 1 for all of the training samples is 0.371. How does this compare in the CV dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for predicting all ones on cv data: 0.3711\n"
     ]
    }
   ],
   "source": [
    "y_cv = R_cv.set_index(['user_id', 'problem_id'])['attempts_range']\n",
    "\n",
    "y_pred = np.ones(len(y_cv))\n",
    "print('F1 score for predicting all ones on cv data: %s' % round(f1(y_cv, y_pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a similar f1 score for predicting all ones on the CV dataset. This is a good indication that there was minimal selection bias in our splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out-of-box Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by building an out-of-box model and try to improve it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765422743464437"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "f1(y_train, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4138444028234788"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_cv)\n",
    "\n",
    "f1(y_cv, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The out-of-box random forest models gives an f1 score of 0.977 on the training data and 0.414 on the cross-validation data. This is already much better than the baseline model! But we're still far from 1. During my exploratory analysis of the data, it was clear that many features were correlated with one another. Before diving into model optimization through hyperparameter tuning, I want to see if removing some of this colinearity between features improves the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by performing PCA on the full dataset to see how many features we can safely remove. Performing PCA on the full dataset has two benefits.\n",
    "\n",
    "1. The dimensionality of the training data is reduced and therefore takes less computation to train the model on.\n",
    "2. Colinear features are removed. The principal components returned by PCA are all orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "type": "scatter",
         "uid": "3ff7d88a-ab60-11e9-aa24-e442a6f8adc6",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171
         ],
         "y": [
          2517982877196999,
          15180755709359.832,
          222566.3188123938,
          55635.73933597019,
          45073.99131683018,
          11617.337531245052,
          579.0112168482756,
          307.80594283305504,
          214.8988665634469,
          202.23600431556176,
          1.5914385672540483,
          1.0172884244356573,
          0.37411440171237487,
          0.321107060042231,
          0.2912963506531572,
          0.280025859949325,
          0.24839401339434658,
          0.217728018781034,
          0.2150428826343267,
          0.20036475884836671,
          0.1806334829693966,
          0.1772825809999196,
          0.15112534073278786,
          0.14663691074185606,
          0.13577933713926962,
          0.12691128019984985,
          0.12101638076420786,
          0.09956775223800923,
          0.09568696691778983,
          0.08266398947507331,
          0.07570649103085547,
          0.07230321087760795,
          0.07073780182795289,
          0.0628212789749589,
          0.05828145224567807,
          0.05019360717826255,
          0.04424905485947827,
          0.04047743902026701,
          0.038430677531696995,
          0.033920007974995246,
          0.030663639896445605,
          0.02930145550286501,
          0.025116966608482387,
          0.02364049495533975,
          0.021661631680812365,
          0.021476767371680423,
          0.019496313208277164,
          0.019306447166507756,
          0.0192017195433755,
          0.018033042124047115,
          0.0176102954370836,
          0.016404431519858147,
          0.016143647474225954,
          0.015029738389595225,
          0.014699475635109378,
          0.014399167836393344,
          0.013493230624300736,
          0.013133486653737174,
          0.012658263582704615,
          0.012099113906091825,
          0.011641539144256259,
          0.01093259353955511,
          0.010253519689252082,
          0.010126065430932038,
          0.009949483836649575,
          0.009012861459247784,
          0.008224513523544039,
          0.007715153500202977,
          0.007680237249475361,
          0.007110154480746208,
          0.007035980046813057,
          0.00671377694088172,
          0.006642089697508462,
          0.006157236828262643,
          0.005973188009661907,
          0.00560260356547624,
          0.00544907198789889,
          0.00536087884046539,
          0.005299500013572238,
          0.0048041675878317995,
          0.0045510848069119396,
          0.004231146734050633,
          0.004105765390658554,
          0.0038476601589619817,
          0.0036077519390801138,
          0.00336716792136021,
          0.0030938684491868085,
          0.002879785696996755,
          0.002837820993551591,
          0.002537293636953792,
          0.0023735984035028615,
          0.0022732514063591755,
          0.002227374635388521,
          0.0021825974078553446,
          0.0020772843150659004,
          0.0019980580575234943,
          0.0019802039952982143,
          0.0019264669605796318,
          0.0018449140701000519,
          0.0018126497959718977,
          0.0018047740003291166,
          0.0017489131335116127,
          0.0016814723748617998,
          0.0016470428131864741,
          0.001625043812169691,
          0.001616679008710091,
          0.0015057106770548924,
          0.0014721318558990248,
          0.0014331356991706388,
          0.0012538630316840623,
          0.0011722874591258382,
          0.0010968028494680938,
          0.0010751343378734215,
          0.001043757841782725,
          0.0010164725287753554,
          0.0009655864266922582,
          0.0009538743363830513,
          0.0009238047845229909,
          0.0008678386831859616,
          0.0008514788119108363,
          0.0008368423257323219,
          0.0008126292531079211,
          0.0007790797584495948,
          0.0007502533948081298,
          0.0007307892208653834,
          0.0007196240303851487,
          0.0007051336808496142,
          0.0005692138388969991,
          0.0005468333555952306,
          0.000523920028325965,
          0.0004611796376482679,
          0.00045063782107082633,
          0.00043978237728730784,
          0.0004341359414512206,
          0.00043055223415601094,
          0.0003993739737460521,
          0.00037460641305790194,
          0.0003701686455816821,
          0.00031261122838648124,
          0.0003065732971640766,
          0.00028364355033463705,
          0.0002699618501480541,
          0.00023249099126282973,
          0.00018076617643159257,
          0.00016207934682500822,
          0.00015491960005176785,
          0.00010334999140639218,
          7.760579432051342e-05,
          3.8826260929413774e-05,
          1.609363126828172e-05,
          6.589980751008954e-07,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.903360676429832e-17,
          1.0308999881165242e-23
         ]
        }
       ],
       "layout": {
        "title": "Explained Variance vs # of Dimensions",
        "xaxis": {
         "title": "# of Dimensions"
        },
        "yaxis": {
         "title": "Explained Variance",
         "type": "log"
        }
       }
      },
      "text/html": [
       "<div id=\"745177df-d1eb-452d-b4fc-2ffa4f002068\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '745177df-d1eb-452d-b4fc-2ffa4f002068',\n",
       "            [{\"mode\": \"lines+markers\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171], \"y\": [2517982877196999.0, 15180755709359.832, 222566.3188123938, 55635.73933597019, 45073.99131683018, 11617.337531245052, 579.0112168482756, 307.80594283305504, 214.8988665634469, 202.23600431556176, 1.5914385672540483, 1.0172884244356573, 0.37411440171237487, 0.321107060042231, 0.2912963506531572, 0.280025859949325, 0.24839401339434658, 0.217728018781034, 0.2150428826343267, 0.20036475884836671, 0.1806334829693966, 0.1772825809999196, 0.15112534073278786, 0.14663691074185606, 0.13577933713926962, 0.12691128019984985, 0.12101638076420786, 0.09956775223800923, 0.09568696691778983, 0.08266398947507331, 0.07570649103085547, 0.07230321087760795, 0.07073780182795289, 0.0628212789749589, 0.05828145224567807, 0.05019360717826255, 0.04424905485947827, 0.04047743902026701, 0.038430677531696995, 0.033920007974995246, 0.030663639896445605, 0.02930145550286501, 0.025116966608482387, 0.02364049495533975, 0.021661631680812365, 0.021476767371680423, 0.019496313208277164, 0.019306447166507756, 0.0192017195433755, 0.018033042124047115, 0.0176102954370836, 0.016404431519858147, 0.016143647474225954, 0.015029738389595225, 0.014699475635109378, 0.014399167836393344, 0.013493230624300736, 0.013133486653737174, 0.012658263582704615, 0.012099113906091825, 0.011641539144256259, 0.01093259353955511, 0.010253519689252082, 0.010126065430932038, 0.009949483836649575, 0.009012861459247784, 0.008224513523544039, 0.007715153500202977, 0.007680237249475361, 0.007110154480746208, 0.007035980046813057, 0.00671377694088172, 0.006642089697508462, 0.006157236828262643, 0.005973188009661907, 0.00560260356547624, 0.00544907198789889, 0.00536087884046539, 0.005299500013572238, 0.0048041675878317995, 0.0045510848069119396, 0.004231146734050633, 0.004105765390658554, 0.0038476601589619817, 0.0036077519390801138, 0.00336716792136021, 0.0030938684491868085, 0.002879785696996755, 0.002837820993551591, 0.002537293636953792, 0.0023735984035028615, 0.0022732514063591755, 0.002227374635388521, 0.0021825974078553446, 0.0020772843150659004, 0.0019980580575234943, 0.0019802039952982143, 0.0019264669605796318, 0.0018449140701000519, 0.0018126497959718977, 0.0018047740003291166, 0.0017489131335116127, 0.0016814723748617998, 0.0016470428131864741, 0.001625043812169691, 0.001616679008710091, 0.0015057106770548924, 0.0014721318558990248, 0.0014331356991706388, 0.0012538630316840623, 0.0011722874591258382, 0.0010968028494680938, 0.0010751343378734215, 0.001043757841782725, 0.0010164725287753554, 0.0009655864266922582, 0.0009538743363830513, 0.0009238047845229909, 0.0008678386831859616, 0.0008514788119108363, 0.0008368423257323219, 0.0008126292531079211, 0.0007790797584495948, 0.0007502533948081298, 0.0007307892208653834, 0.0007196240303851487, 0.0007051336808496142, 0.0005692138388969991, 0.0005468333555952306, 0.000523920028325965, 0.0004611796376482679, 0.00045063782107082633, 0.00043978237728730784, 0.0004341359414512206, 0.00043055223415601094, 0.0003993739737460521, 0.00037460641305790194, 0.0003701686455816821, 0.00031261122838648124, 0.0003065732971640766, 0.00028364355033463705, 0.0002699618501480541, 0.00023249099126282973, 0.00018076617643159257, 0.00016207934682500822, 0.00015491960005176785, 0.00010334999140639218, 7.760579432051342e-05, 3.8826260929413774e-05, 1.609363126828172e-05, 6.589980751008954e-07, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.0308999881165242e-23], \"type\": \"scatter\", \"uid\": \"3ff7d88a-ab60-11e9-aa24-e442a6f8adc6\"}],\n",
       "            {\"title\": \"Explained Variance vs # of Dimensions\", \"xaxis\": {\"title\": \"# of Dimensions\"}, \"yaxis\": {\"title\": \"Explained Variance\", \"type\": \"log\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('745177df-d1eb-452d-b4fc-2ffa4f002068',{});}).then(function(){Plotly.animate('745177df-d1eb-452d-b4fc-2ffa4f002068');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"745177df-d1eb-452d-b4fc-2ffa4f002068\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '745177df-d1eb-452d-b4fc-2ffa4f002068',\n",
       "            [{\"mode\": \"lines+markers\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171], \"y\": [2517982877196999.0, 15180755709359.832, 222566.3188123938, 55635.73933597019, 45073.99131683018, 11617.337531245052, 579.0112168482756, 307.80594283305504, 214.8988665634469, 202.23600431556176, 1.5914385672540483, 1.0172884244356573, 0.37411440171237487, 0.321107060042231, 0.2912963506531572, 0.280025859949325, 0.24839401339434658, 0.217728018781034, 0.2150428826343267, 0.20036475884836671, 0.1806334829693966, 0.1772825809999196, 0.15112534073278786, 0.14663691074185606, 0.13577933713926962, 0.12691128019984985, 0.12101638076420786, 0.09956775223800923, 0.09568696691778983, 0.08266398947507331, 0.07570649103085547, 0.07230321087760795, 0.07073780182795289, 0.0628212789749589, 0.05828145224567807, 0.05019360717826255, 0.04424905485947827, 0.04047743902026701, 0.038430677531696995, 0.033920007974995246, 0.030663639896445605, 0.02930145550286501, 0.025116966608482387, 0.02364049495533975, 0.021661631680812365, 0.021476767371680423, 0.019496313208277164, 0.019306447166507756, 0.0192017195433755, 0.018033042124047115, 0.0176102954370836, 0.016404431519858147, 0.016143647474225954, 0.015029738389595225, 0.014699475635109378, 0.014399167836393344, 0.013493230624300736, 0.013133486653737174, 0.012658263582704615, 0.012099113906091825, 0.011641539144256259, 0.01093259353955511, 0.010253519689252082, 0.010126065430932038, 0.009949483836649575, 0.009012861459247784, 0.008224513523544039, 0.007715153500202977, 0.007680237249475361, 0.007110154480746208, 0.007035980046813057, 0.00671377694088172, 0.006642089697508462, 0.006157236828262643, 0.005973188009661907, 0.00560260356547624, 0.00544907198789889, 0.00536087884046539, 0.005299500013572238, 0.0048041675878317995, 0.0045510848069119396, 0.004231146734050633, 0.004105765390658554, 0.0038476601589619817, 0.0036077519390801138, 0.00336716792136021, 0.0030938684491868085, 0.002879785696996755, 0.002837820993551591, 0.002537293636953792, 0.0023735984035028615, 0.0022732514063591755, 0.002227374635388521, 0.0021825974078553446, 0.0020772843150659004, 0.0019980580575234943, 0.0019802039952982143, 0.0019264669605796318, 0.0018449140701000519, 0.0018126497959718977, 0.0018047740003291166, 0.0017489131335116127, 0.0016814723748617998, 0.0016470428131864741, 0.001625043812169691, 0.001616679008710091, 0.0015057106770548924, 0.0014721318558990248, 0.0014331356991706388, 0.0012538630316840623, 0.0011722874591258382, 0.0010968028494680938, 0.0010751343378734215, 0.001043757841782725, 0.0010164725287753554, 0.0009655864266922582, 0.0009538743363830513, 0.0009238047845229909, 0.0008678386831859616, 0.0008514788119108363, 0.0008368423257323219, 0.0008126292531079211, 0.0007790797584495948, 0.0007502533948081298, 0.0007307892208653834, 0.0007196240303851487, 0.0007051336808496142, 0.0005692138388969991, 0.0005468333555952306, 0.000523920028325965, 0.0004611796376482679, 0.00045063782107082633, 0.00043978237728730784, 0.0004341359414512206, 0.00043055223415601094, 0.0003993739737460521, 0.00037460641305790194, 0.0003701686455816821, 0.00031261122838648124, 0.0003065732971640766, 0.00028364355033463705, 0.0002699618501480541, 0.00023249099126282973, 0.00018076617643159257, 0.00016207934682500822, 0.00015491960005176785, 0.00010334999140639218, 7.760579432051342e-05, 3.8826260929413774e-05, 1.609363126828172e-05, 6.589980751008954e-07, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.903360676429832e-17, 1.0308999881165242e-23], \"type\": \"scatter\", \"uid\": \"3ff7d88a-ab60-11e9-aa24-e442a6f8adc6\"}],\n",
       "            {\"title\": \"Explained Variance vs # of Dimensions\", \"xaxis\": {\"title\": \"# of Dimensions\"}, \"yaxis\": {\"title\": \"Explained Variance\", \"type\": \"log\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('745177df-d1eb-452d-b4fc-2ffa4f002068',{});}).then(function(){Plotly.animate('745177df-d1eb-452d-b4fc-2ffa4f002068');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "\n",
    "x = list(range(1, len(pca.explained_variance_)+1))\n",
    "y = pca.explained_variance_\n",
    "\n",
    "trace0 = go.Scatter(x=x, y=y, mode='lines+markers')\n",
    "\n",
    "layout = go.Layout(title='Explained Variance vs # of Dimensions',\n",
    "                  xaxis=dict(title='# of Dimensions'),\n",
    "                  yaxis=dict(title='Explained Variance', type='log'))\n",
    "\n",
    "fig = go.Figure([trace0], layout)\n",
    "\n",
    "iplot(fig, filename='explained-var_vs_N-dimensions.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n",
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n",
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n",
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n",
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n",
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n",
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components=[1,2,5,10,25,50,100]\n",
    "\n",
    "f1_scores = []\n",
    "for n in n_components:\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    \n",
    "    X_train_r = pca.fit_transform(X_train)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "    clf.fit(X_train_r, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_train_r)\n",
    "\n",
    "    f1_scores.append(f1(y_train, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "type": "scatter",
         "uid": "7a0dba7e-ab61-11e9-b9e0-e442a6f8adc6",
         "x": [
          1,
          2,
          5,
          10,
          25,
          50,
          100
         ],
         "y": [
          0.46898265081543267,
          0.4694214535688021,
          0.9577273455302155,
          0.9504308815111825,
          0.9780461463262689,
          0.978968914309074,
          0.9793502188253496
         ]
        }
       ],
       "layout": {
        "title": "F1 Score vs Principal Components",
        "xaxis": {
         "title": "Principal Components"
        },
        "yaxis": {
         "title": "F1 Score",
         "type": "log"
        }
       }
      },
      "text/html": [
       "<div id=\"90ef1401-37a5-47ef-a886-8032be50eeee\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '90ef1401-37a5-47ef-a886-8032be50eeee',\n",
       "            [{\"mode\": \"lines+markers\", \"x\": [1, 2, 5, 10, 25, 50, 100], \"y\": [0.46898265081543267, 0.4694214535688021, 0.9577273455302155, 0.9504308815111825, 0.9780461463262689, 0.978968914309074, 0.9793502188253496], \"type\": \"scatter\", \"uid\": \"7a0dba7e-ab61-11e9-b9e0-e442a6f8adc6\"}],\n",
       "            {\"title\": \"F1 Score vs Principal Components\", \"xaxis\": {\"title\": \"Principal Components\"}, \"yaxis\": {\"title\": \"F1 Score\", \"type\": \"log\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('90ef1401-37a5-47ef-a886-8032be50eeee',{});}).then(function(){Plotly.animate('90ef1401-37a5-47ef-a886-8032be50eeee');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"90ef1401-37a5-47ef-a886-8032be50eeee\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '90ef1401-37a5-47ef-a886-8032be50eeee',\n",
       "            [{\"mode\": \"lines+markers\", \"x\": [1, 2, 5, 10, 25, 50, 100], \"y\": [0.46898265081543267, 0.4694214535688021, 0.9577273455302155, 0.9504308815111825, 0.9780461463262689, 0.978968914309074, 0.9793502188253496], \"type\": \"scatter\", \"uid\": \"7a0dba7e-ab61-11e9-b9e0-e442a6f8adc6\"}],\n",
       "            {\"title\": \"F1 Score vs Principal Components\", \"xaxis\": {\"title\": \"Principal Components\"}, \"yaxis\": {\"title\": \"F1 Score\", \"type\": \"log\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('90ef1401-37a5-47ef-a886-8032be50eeee',{});}).then(function(){Plotly.animate('90ef1401-37a5-47ef-a886-8032be50eeee');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace0 = go.Scatter(x=n_components, y=f1_scores, mode='lines+markers')\n",
    "\n",
    "layout = go.Layout(title='F1 Score vs Principal Components',\n",
    "                  xaxis=dict(title='Principal Components'),\n",
    "                  yaxis=dict(title='F1 Score', type='log'))\n",
    "\n",
    "fig = go.Figure([trace0], layout)\n",
    "\n",
    "iplot(fig, filename='f1_score-vs-principal_components.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that at a number of principal components less than 25, there is a significant hit in the F1 score. Above 25 principal components, there seems to be a negligible difference. In general, there is no improvement over the baseline model when using PCA to remove colinear features and reduce the dataset's dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use GridSearhCV to try to tune the hyperparameters of the model. Rather than passing a large dictionary object of all the hyperparameters we want to tune at once, I will explore each of the hyperparameters individually. This will make it more straightforward when interpretting the effects of each hyperparameter. At the end, I will then pass all of the hyperparameters to GridSearchCV to find the optimal combination of all hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators defines how many trees the model will have. Generally, the more trees the better the model will generalize. However more trees equals more computation and therefore we want to strike a balance between fit to the test data and train + test times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With GridSearchCV, we can define the scoring function. Since we want to maximize the f1_score function with \"weighted\" averaging from sklearn.metrics, we pass this same scoring function to GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'n_estimators': [5, 10, 50, 100, 150, 200, 250]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_estimators': [5,10,50,100,150,200,250]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the search are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6.869155</td>\n",
       "      <td>0.445677</td>\n",
       "      <td>0.939287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>15.427733</td>\n",
       "      <td>0.454690</td>\n",
       "      <td>0.977563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>45.935924</td>\n",
       "      <td>0.458341</td>\n",
       "      <td>0.999641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>49.879743</td>\n",
       "      <td>0.461532</td>\n",
       "      <td>0.999872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>67.730156</td>\n",
       "      <td>0.461941</td>\n",
       "      <td>0.999891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>71.066319</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.999891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250</td>\n",
       "      <td>69.040377</td>\n",
       "      <td>0.461822</td>\n",
       "      <td>0.999891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  combined_mean_fit-test_time  mean_test_score  \\\n",
       "0             5                     6.869155         0.445677   \n",
       "1            10                    15.427733         0.454690   \n",
       "2            50                    45.935924         0.458341   \n",
       "3           100                    49.879743         0.461532   \n",
       "4           150                    67.730156         0.461941   \n",
       "5           200                    71.066319         0.462222   \n",
       "6           250                    69.040377         0.461822   \n",
       "\n",
       "   mean_train_score  \n",
       "0          0.939287  \n",
       "1          0.977563  \n",
       "2          0.999641  \n",
       "3          0.999872  \n",
       "4          0.999891  \n",
       "5          0.999891  \n",
       "6          0.999891  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'n_estimators' : [5,10,50,100,150,200,250],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the train and test scores as a function of N_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "name": "Mean Test Score",
         "type": "scattergl",
         "uid": "4776a22e-ab62-11e9-a551-e442a6f8adc6",
         "x": [
          5,
          10,
          50,
          100,
          150,
          200,
          250
         ],
         "y": [
          0.4456773691497722,
          0.45469005233055837,
          0.4583410870974602,
          0.4615317823724039,
          0.4619413993833244,
          0.4622222565920168,
          0.4618221158728386
         ],
         "yaxis": "y2"
        },
        {
         "mode": "lines+markers",
         "name": "Mean Train Score",
         "type": "scattergl",
         "uid": "4776a22f-ab62-11e9-88d4-e442a6f8adc6",
         "x": [
          5,
          10,
          50,
          100,
          150,
          200,
          250
         ],
         "y": [
          0.9392869135698426,
          0.9775629760234092,
          0.99964116709982,
          0.9998718496402608,
          0.9998910719581369,
          0.9998910714360845,
          0.9998910720813086
         ]
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h",
         "y": 1.12
        },
        "margin": {
         "t": 120
        },
        "title": "Mean Train & Test Scores vs N_estimators",
        "xaxis": {
         "title": "N_estimators"
        },
        "yaxis": {
         "title": "Mean Train Score"
        },
        "yaxis2": {
         "side": "right",
         "title": "Mean Test Score"
        }
       }
      },
      "text/html": [
       "<div id=\"877a15de-d536-4274-ad7a-2aa96e34bfba\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '877a15de-d536-4274-ad7a-2aa96e34bfba',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0, 200.0, 250.0], \"y\": [0.4456773691497722, 0.45469005233055837, 0.4583410870974602, 0.4615317823724039, 0.4619413993833244, 0.4622222565920168, 0.4618221158728386], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"4776a22e-ab62-11e9-a551-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Train Score\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0, 200.0, 250.0], \"y\": [0.9392869135698426, 0.9775629760234092, 0.99964116709982, 0.9998718496402608, 0.9998910719581369, 0.9998910714360845, 0.9998910720813086], \"type\": \"scattergl\", \"uid\": \"4776a22f-ab62-11e9-88d4-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Mean Train & Test Scores vs N_estimators\", \"xaxis\": {\"title\": \"N_estimators\"}, \"yaxis\": {\"title\": \"Mean Train Score\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('877a15de-d536-4274-ad7a-2aa96e34bfba',{});}).then(function(){Plotly.animate('877a15de-d536-4274-ad7a-2aa96e34bfba');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"877a15de-d536-4274-ad7a-2aa96e34bfba\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '877a15de-d536-4274-ad7a-2aa96e34bfba',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0, 200.0, 250.0], \"y\": [0.4456773691497722, 0.45469005233055837, 0.4583410870974602, 0.4615317823724039, 0.4619413993833244, 0.4622222565920168, 0.4618221158728386], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"4776a22e-ab62-11e9-a551-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Train Score\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0, 200.0, 250.0], \"y\": [0.9392869135698426, 0.9775629760234092, 0.99964116709982, 0.9998718496402608, 0.9998910719581369, 0.9998910714360845, 0.9998910720813086], \"type\": \"scattergl\", \"uid\": \"4776a22f-ab62-11e9-88d4-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Mean Train & Test Scores vs N_estimators\", \"xaxis\": {\"title\": \"N_estimators\"}, \"yaxis\": {\"title\": \"Mean Train Score\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('877a15de-d536-4274-ad7a-2aa96e34bfba',{});}).then(function(){Plotly.animate('877a15de-d536-4274-ad7a-2aa96e34bfba');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace1 = go.Scattergl(name='Mean Test Score',\n",
    "                      x=results['n_estimators'],\n",
    "                      y=results['mean_test_score'], \n",
    "                      mode='lines+markers',\n",
    "                     yaxis='y2')\n",
    "trace2 = go.Scattergl(name='Mean Train Score',\n",
    "                      x=results['n_estimators'],\n",
    "                      y=results['mean_train_score'], \n",
    "                      mode='lines+markers')\n",
    "\n",
    "layout = go.Layout(title='Mean Train & Test Scores vs N_estimators',\n",
    "               xaxis=dict(title='N_estimators'),\n",
    "               yaxis=dict(title='Mean Train Score'), \n",
    "                   yaxis2=dict(title='Mean Test Score',\n",
    "                              side='right'),\n",
    "                  legend=dict(orientation='h', y=1.12),\n",
    "                  margin=dict(t=120))\n",
    "\n",
    "fig = go.Figure([trace1, trace2], layout=layout)\n",
    "\n",
    "iplot(fig, filename='train-test-scores.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see both scores increase in going from 5 to 100 estimators but quickly plateau after that. The train and test scores are plotted on separate axes above so we can distinguish the knees of both curves. We can see that the training score is very close to 1, even for n_estimators=5. The more important score of course is the test score. Let's now look at the tradeoff between the test score and the time required to train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv(df, param):\n",
    "    trace0 = go.Scattergl(name='Combined Mean Train+Test Time',\n",
    "                      x=results[param],\n",
    "                      y=results['combined_mean_fit-test_time'], \n",
    "                      mode='lines+markers',)\n",
    "    trace1 = go.Scattergl(name='Mean Test Score',\n",
    "                          x=results[param],\n",
    "                          y=results['mean_test_score'], \n",
    "                          mode='lines+markers',\n",
    "                         yaxis='y2')\n",
    "\n",
    "    layout = go.Layout(title='Model Train+Test Time & Test Score vs %s' % param,\n",
    "                   xaxis=dict(title=param),\n",
    "                   yaxis=dict(title='Combined Train+Test Time'), \n",
    "                       yaxis2=dict(title='Mean Test Score',\n",
    "                                  side='right'),\n",
    "                      legend=dict(orientation='h', y=1.12),\n",
    "                      margin=dict(t=120))\n",
    "\n",
    "    fig = go.Figure([trace0, trace1], layout=layout)\n",
    "\n",
    "    iplot(fig, filename='%s.html' % param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "name": "Combined Mean Train+Test Time",
         "type": "scattergl",
         "uid": "97b514f4-ab6c-11e9-8135-e442a6f8adc6",
         "x": [
          5,
          10,
          50,
          100,
          150,
          200,
          250
         ],
         "y": [
          6.8691552639007565,
          15.427732801437378,
          45.93592410087586,
          49.87974262237549,
          67.73015632629395,
          71.06631932258605,
          69.04037733078003
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Mean Test Score",
         "type": "scattergl",
         "uid": "97b514f5-ab6c-11e9-a03e-e442a6f8adc6",
         "x": [
          5,
          10,
          50,
          100,
          150,
          200,
          250
         ],
         "y": [
          0.4456773691497722,
          0.45469005233055837,
          0.4583410870974602,
          0.4615317823724039,
          0.4619413993833244,
          0.4622222565920168,
          0.4618221158728386
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h",
         "y": 1.12
        },
        "margin": {
         "t": 120
        },
        "title": "Model Train+Test Time & Test Score vs n_estimators",
        "xaxis": {
         "title": "n_estimators"
        },
        "yaxis": {
         "title": "Combined Train+Test Time"
        },
        "yaxis2": {
         "side": "right",
         "title": "Mean Test Score"
        }
       }
      },
      "text/html": [
       "<div id=\"9b0bc9a8-2f6e-4f92-b8fd-4f90879caa47\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '9b0bc9a8-2f6e-4f92-b8fd-4f90879caa47',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Combined Mean Train+Test Time\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0, 200.0, 250.0], \"y\": [6.8691552639007565, 15.427732801437378, 45.93592410087586, 49.87974262237549, 67.73015632629395, 71.06631932258605, 69.04037733078003], \"type\": \"scattergl\", \"uid\": \"97b514f4-ab6c-11e9-8135-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0, 200.0, 250.0], \"y\": [0.4456773691497722, 0.45469005233055837, 0.4583410870974602, 0.4615317823724039, 0.4619413993833244, 0.4622222565920168, 0.4618221158728386], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"97b514f5-ab6c-11e9-a03e-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Model Train+Test Time & Test Score vs n_estimators\", \"xaxis\": {\"title\": \"n_estimators\"}, \"yaxis\": {\"title\": \"Combined Train+Test Time\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('9b0bc9a8-2f6e-4f92-b8fd-4f90879caa47',{});}).then(function(){Plotly.animate('9b0bc9a8-2f6e-4f92-b8fd-4f90879caa47');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"9b0bc9a8-2f6e-4f92-b8fd-4f90879caa47\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '9b0bc9a8-2f6e-4f92-b8fd-4f90879caa47',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Combined Mean Train+Test Time\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0, 200.0, 250.0], \"y\": [6.8691552639007565, 15.427732801437378, 45.93592410087586, 49.87974262237549, 67.73015632629395, 71.06631932258605, 69.04037733078003], \"type\": \"scattergl\", \"uid\": \"97b514f4-ab6c-11e9-8135-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0, 200.0, 250.0], \"y\": [0.4456773691497722, 0.45469005233055837, 0.4583410870974602, 0.4615317823724039, 0.4619413993833244, 0.4622222565920168, 0.4618221158728386], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"97b514f5-ab6c-11e9-a03e-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Model Train+Test Time & Test Score vs n_estimators\", \"xaxis\": {\"title\": \"n_estimators\"}, \"yaxis\": {\"title\": \"Combined Train+Test Time\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('9b0bc9a8-2f6e-4f92-b8fd-4f90879caa47',{});}).then(function(){Plotly.animate('9b0bc9a8-2f6e-4f92-b8fd-4f90879caa47');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cv(results, param='n_estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the combined time for training and testing the model increases significantly up to 109 seconds at N_estimators=150. At N_estimators=100, the train+test time is 65 seconds but the difference in test score between the two is negligible. We can thus save a lot of computational resources and time by choosing N_estimators=100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10, 50, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'max_depth': [5,10,50,100,150]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1.184245</td>\n",
       "      <td>0.386043</td>\n",
       "      <td>0.395494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2.153944</td>\n",
       "      <td>0.457967</td>\n",
       "      <td>0.501100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3.667719</td>\n",
       "      <td>0.451553</td>\n",
       "      <td>0.977570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>3.872194</td>\n",
       "      <td>0.454690</td>\n",
       "      <td>0.977563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>4.082100</td>\n",
       "      <td>0.454690</td>\n",
       "      <td>0.977563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  combined_mean_fit-test_time  mean_test_score  mean_train_score\n",
       "0          5                     1.184245         0.386043          0.395494\n",
       "1         10                     2.153944         0.457967          0.501100\n",
       "2         50                     3.667719         0.451553          0.977570\n",
       "3        100                     3.872194         0.454690          0.977563\n",
       "4        150                     4.082100         0.454690          0.977563"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'max_depth' : [5,10,50,100,150],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "name": "Combined Mean Train+Test Time",
         "type": "scattergl",
         "uid": "9f654246-ab6c-11e9-92b7-e442a6f8adc6",
         "x": [
          5,
          10,
          50,
          100,
          150
         ],
         "y": [
          1.184245491027832,
          2.1539438724517823,
          3.667719316482544,
          3.872193717956543,
          4.082100296020508
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Mean Test Score",
         "type": "scattergl",
         "uid": "9f654247-ab6c-11e9-8ea5-e442a6f8adc6",
         "x": [
          5,
          10,
          50,
          100,
          150
         ],
         "y": [
          0.38604263688008356,
          0.45796737308050345,
          0.4515532331391779,
          0.45469005233055837,
          0.45469005233055837
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h",
         "y": 1.12
        },
        "margin": {
         "t": 120
        },
        "title": "Model Train+Test Time & Test Score vs max_depth",
        "xaxis": {
         "title": "max_depth"
        },
        "yaxis": {
         "title": "Combined Train+Test Time"
        },
        "yaxis2": {
         "side": "right",
         "title": "Mean Test Score"
        }
       }
      },
      "text/html": [
       "<div id=\"95e9b266-36ac-4ef0-b52a-5f81336890cd\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '95e9b266-36ac-4ef0-b52a-5f81336890cd',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Combined Mean Train+Test Time\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0], \"y\": [1.184245491027832, 2.1539438724517823, 3.667719316482544, 3.872193717956543, 4.082100296020508], \"type\": \"scattergl\", \"uid\": \"9f654246-ab6c-11e9-92b7-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0], \"y\": [0.38604263688008356, 0.45796737308050345, 0.4515532331391779, 0.45469005233055837, 0.45469005233055837], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"9f654247-ab6c-11e9-8ea5-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Model Train+Test Time & Test Score vs max_depth\", \"xaxis\": {\"title\": \"max_depth\"}, \"yaxis\": {\"title\": \"Combined Train+Test Time\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('95e9b266-36ac-4ef0-b52a-5f81336890cd',{});}).then(function(){Plotly.animate('95e9b266-36ac-4ef0-b52a-5f81336890cd');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"95e9b266-36ac-4ef0-b52a-5f81336890cd\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '95e9b266-36ac-4ef0-b52a-5f81336890cd',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Combined Mean Train+Test Time\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0], \"y\": [1.184245491027832, 2.1539438724517823, 3.667719316482544, 3.872193717956543, 4.082100296020508], \"type\": \"scattergl\", \"uid\": \"9f654246-ab6c-11e9-92b7-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [5.0, 10.0, 50.0, 100.0, 150.0], \"y\": [0.38604263688008356, 0.45796737308050345, 0.4515532331391779, 0.45469005233055837, 0.45469005233055837], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"9f654247-ab6c-11e9-8ea5-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Model Train+Test Time & Test Score vs max_depth\", \"xaxis\": {\"title\": \"max_depth\"}, \"yaxis\": {\"title\": \"Combined Train+Test Time\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('95e9b266-36ac-4ef0-b52a-5f81336890cd',{});}).then(function(){Plotly.animate('95e9b266-36ac-4ef0-b52a-5f81336890cd');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cv(results, param='max_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'min_samples_split': [2, 3, 4, 5, 10, 25, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'min_samples_split': [2,3,4,5,10,25,50,100]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4.979714</td>\n",
       "      <td>0.454690</td>\n",
       "      <td>0.977563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4.614216</td>\n",
       "      <td>0.456383</td>\n",
       "      <td>0.953491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7.281724</td>\n",
       "      <td>0.457113</td>\n",
       "      <td>0.925452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6.423782</td>\n",
       "      <td>0.459216</td>\n",
       "      <td>0.898678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>6.836548</td>\n",
       "      <td>0.461343</td>\n",
       "      <td>0.797194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>7.482361</td>\n",
       "      <td>0.469938</td>\n",
       "      <td>0.673634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>5.751819</td>\n",
       "      <td>0.469966</td>\n",
       "      <td>0.609777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2.556550</td>\n",
       "      <td>0.472612</td>\n",
       "      <td>0.567468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_samples_split  combined_mean_fit-test_time  mean_test_score  \\\n",
       "0                  2                     4.979714         0.454690   \n",
       "1                  3                     4.614216         0.456383   \n",
       "2                  4                     7.281724         0.457113   \n",
       "3                  5                     6.423782         0.459216   \n",
       "4                 10                     6.836548         0.461343   \n",
       "5                 25                     7.482361         0.469938   \n",
       "6                 50                     5.751819         0.469966   \n",
       "7                100                     2.556550         0.472612   \n",
       "\n",
       "   mean_train_score  \n",
       "0          0.977563  \n",
       "1          0.953491  \n",
       "2          0.925452  \n",
       "3          0.898678  \n",
       "4          0.797194  \n",
       "5          0.673634  \n",
       "6          0.609777  \n",
       "7          0.567468  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'min_samples_split' : [2,3,4,5,10,25,50,100],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "name": "Combined Mean Train+Test Time",
         "type": "scattergl",
         "uid": "2f2ccdec-ab6e-11e9-8341-e442a6f8adc6",
         "x": [
          2,
          3,
          4,
          5,
          10,
          25,
          50,
          100
         ],
         "y": [
          4.979714393615723,
          4.614215946197509,
          7.281723976135254,
          6.4237815856933596,
          6.83654751777649,
          7.482361316680908,
          5.751819086074828,
          2.556549596786499
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Mean Test Score",
         "type": "scattergl",
         "uid": "2f2ccded-ab6e-11e9-b369-e442a6f8adc6",
         "x": [
          2,
          3,
          4,
          5,
          10,
          25,
          50,
          100
         ],
         "y": [
          0.45469005233055837,
          0.45638320719140624,
          0.4571130622321975,
          0.4592160604369924,
          0.46134327637530553,
          0.4699383014637487,
          0.4699663487234894,
          0.4726117081226787
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h",
         "y": 1.12
        },
        "margin": {
         "t": 120
        },
        "title": "Model Train+Test Time & Test Score vs min_samples_split",
        "xaxis": {
         "title": "min_samples_split"
        },
        "yaxis": {
         "title": "Combined Train+Test Time"
        },
        "yaxis2": {
         "side": "right",
         "title": "Mean Test Score"
        }
       }
      },
      "text/html": [
       "<div id=\"9a6e160d-d526-4bf3-80d8-38f69d9538d3\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '9a6e160d-d526-4bf3-80d8-38f69d9538d3',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Combined Mean Train+Test Time\", \"x\": [2.0, 3.0, 4.0, 5.0, 10.0, 25.0, 50.0, 100.0], \"y\": [4.979714393615723, 4.614215946197509, 7.281723976135254, 6.4237815856933596, 6.83654751777649, 7.482361316680908, 5.751819086074828, 2.556549596786499], \"type\": \"scattergl\", \"uid\": \"2f2ccdec-ab6e-11e9-8341-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [2.0, 3.0, 4.0, 5.0, 10.0, 25.0, 50.0, 100.0], \"y\": [0.45469005233055837, 0.45638320719140624, 0.4571130622321975, 0.4592160604369924, 0.46134327637530553, 0.4699383014637487, 0.4699663487234894, 0.4726117081226787], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"2f2ccded-ab6e-11e9-b369-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Model Train+Test Time & Test Score vs min_samples_split\", \"xaxis\": {\"title\": \"min_samples_split\"}, \"yaxis\": {\"title\": \"Combined Train+Test Time\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('9a6e160d-d526-4bf3-80d8-38f69d9538d3',{});}).then(function(){Plotly.animate('9a6e160d-d526-4bf3-80d8-38f69d9538d3');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"9a6e160d-d526-4bf3-80d8-38f69d9538d3\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '9a6e160d-d526-4bf3-80d8-38f69d9538d3',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Combined Mean Train+Test Time\", \"x\": [2.0, 3.0, 4.0, 5.0, 10.0, 25.0, 50.0, 100.0], \"y\": [4.979714393615723, 4.614215946197509, 7.281723976135254, 6.4237815856933596, 6.83654751777649, 7.482361316680908, 5.751819086074828, 2.556549596786499], \"type\": \"scattergl\", \"uid\": \"2f2ccdec-ab6e-11e9-8341-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [2.0, 3.0, 4.0, 5.0, 10.0, 25.0, 50.0, 100.0], \"y\": [0.45469005233055837, 0.45638320719140624, 0.4571130622321975, 0.4592160604369924, 0.46134327637530553, 0.4699383014637487, 0.4699663487234894, 0.4726117081226787], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"2f2ccded-ab6e-11e9-b369-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Model Train+Test Time & Test Score vs min_samples_split\", \"xaxis\": {\"title\": \"min_samples_split\"}, \"yaxis\": {\"title\": \"Combined Train+Test Time\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('9a6e160d-d526-4bf3-80d8-38f69d9538d3',{});}).then(function(){Plotly.animate('9a6e160d-d526-4bf3-80d8-38f69d9538d3');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cv(results, param='min_samples_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [2, 3, 4, 5, 10, 25, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'min_samples_leaf': [2,3,4,5,10,25,50,100]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3.406829</td>\n",
       "      <td>0.463485</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4.886431</td>\n",
       "      <td>0.467943</td>\n",
       "      <td>0.707209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4.875672</td>\n",
       "      <td>0.473468</td>\n",
       "      <td>0.660642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5.841019</td>\n",
       "      <td>0.472296</td>\n",
       "      <td>0.631772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>6.360712</td>\n",
       "      <td>0.475734</td>\n",
       "      <td>0.570989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>6.272631</td>\n",
       "      <td>0.476157</td>\n",
       "      <td>0.530147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>3.475947</td>\n",
       "      <td>0.469165</td>\n",
       "      <td>0.505283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>1.769653</td>\n",
       "      <td>0.458407</td>\n",
       "      <td>0.489062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_samples_leaf  combined_mean_fit-test_time  mean_test_score  \\\n",
       "0                 2                     3.406829         0.463485   \n",
       "1                 3                     4.886431         0.467943   \n",
       "2                 4                     4.875672         0.473468   \n",
       "3                 5                     5.841019         0.472296   \n",
       "4                10                     6.360712         0.475734   \n",
       "5                25                     6.272631         0.476157   \n",
       "6                50                     3.475947         0.469165   \n",
       "7               100                     1.769653         0.458407   \n",
       "\n",
       "   mean_train_score  \n",
       "0          0.800847  \n",
       "1          0.707209  \n",
       "2          0.660642  \n",
       "3          0.631772  \n",
       "4          0.570989  \n",
       "5          0.530147  \n",
       "6          0.505283  \n",
       "7          0.489062  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'min_samples_leaf' : [2,3,4,5,10,25,50,100],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid=True, n_jobs=-1, param_grid={'criterion': ['gini', 'entropy']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'criterion': [\"gini\", \"entropy\"]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>2.810248</td>\n",
       "      <td>0.454690</td>\n",
       "      <td>0.977563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3.061918</td>\n",
       "      <td>0.457913</td>\n",
       "      <td>0.977492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion  combined_mean_fit-test_time  mean_test_score  mean_train_score\n",
       "0      gini                     2.810248         0.454690          0.977563\n",
       "1   entropy                     3.061918         0.457913          0.977492"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'criterion' : ['gini', 'entropy'],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'max_features': [2, 10, 25, 50, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'max_features': [2, 10, 25, 50, 100, 150]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4.848548</td>\n",
       "      <td>0.442138</td>\n",
       "      <td>0.977411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>7.120961</td>\n",
       "      <td>0.451855</td>\n",
       "      <td>0.977219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>11.454638</td>\n",
       "      <td>0.454837</td>\n",
       "      <td>0.977082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>11.927170</td>\n",
       "      <td>0.459322</td>\n",
       "      <td>0.976144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>12.584168</td>\n",
       "      <td>0.462525</td>\n",
       "      <td>0.975420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150</td>\n",
       "      <td>12.967173</td>\n",
       "      <td>0.459076</td>\n",
       "      <td>0.975125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features  combined_mean_fit-test_time  mean_test_score  \\\n",
       "0             2                     4.848548         0.442138   \n",
       "1            10                     7.120961         0.451855   \n",
       "2            25                    11.454638         0.454837   \n",
       "3            50                    11.927170         0.459322   \n",
       "4           100                    12.584168         0.462525   \n",
       "5           150                    12.967173         0.459076   \n",
       "\n",
       "   mean_train_score  \n",
       "0          0.977411  \n",
       "1          0.977219  \n",
       "2          0.977082  \n",
       "3          0.976144  \n",
       "4          0.975420  \n",
       "5          0.975125  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'max_features': [2, 10, 25, 50, 100, 150],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "name": "Combined Mean Train+Test Time",
         "type": "scattergl",
         "uid": "783bd958-ab6e-11e9-8221-e442a6f8adc6",
         "x": [
          2,
          10,
          25,
          50,
          100,
          150
         ],
         "y": [
          4.848548126220703,
          7.120961475372315,
          11.454638290405274,
          11.927170181274414,
          12.584168195724487,
          12.967172908782958
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Mean Test Score",
         "type": "scattergl",
         "uid": "783bd959-ab6e-11e9-9f6f-e442a6f8adc6",
         "x": [
          2,
          10,
          25,
          50,
          100,
          150
         ],
         "y": [
          0.44213819449742653,
          0.4518551455961089,
          0.45483738272274193,
          0.45932204001794746,
          0.4625254548949771,
          0.4590757909579968
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h",
         "y": 1.12
        },
        "margin": {
         "t": 120
        },
        "title": "Model Train+Test Time & Test Score vs max_features",
        "xaxis": {
         "title": "max_features"
        },
        "yaxis": {
         "title": "Combined Train+Test Time"
        },
        "yaxis2": {
         "side": "right",
         "title": "Mean Test Score"
        }
       }
      },
      "text/html": [
       "<div id=\"0a42e936-98a7-420e-8fbc-dc87f791750a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '0a42e936-98a7-420e-8fbc-dc87f791750a',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Combined Mean Train+Test Time\", \"x\": [2.0, 10.0, 25.0, 50.0, 100.0, 150.0], \"y\": [4.848548126220703, 7.120961475372315, 11.454638290405274, 11.927170181274414, 12.584168195724487, 12.967172908782958], \"type\": \"scattergl\", \"uid\": \"783bd958-ab6e-11e9-8221-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [2.0, 10.0, 25.0, 50.0, 100.0, 150.0], \"y\": [0.44213819449742653, 0.4518551455961089, 0.45483738272274193, 0.45932204001794746, 0.4625254548949771, 0.4590757909579968], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"783bd959-ab6e-11e9-9f6f-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Model Train+Test Time & Test Score vs max_features\", \"xaxis\": {\"title\": \"max_features\"}, \"yaxis\": {\"title\": \"Combined Train+Test Time\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('0a42e936-98a7-420e-8fbc-dc87f791750a',{});}).then(function(){Plotly.animate('0a42e936-98a7-420e-8fbc-dc87f791750a');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"0a42e936-98a7-420e-8fbc-dc87f791750a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '0a42e936-98a7-420e-8fbc-dc87f791750a',\n",
       "            [{\"mode\": \"lines+markers\", \"name\": \"Combined Mean Train+Test Time\", \"x\": [2.0, 10.0, 25.0, 50.0, 100.0, 150.0], \"y\": [4.848548126220703, 7.120961475372315, 11.454638290405274, 11.927170181274414, 12.584168195724487, 12.967172908782958], \"type\": \"scattergl\", \"uid\": \"783bd958-ab6e-11e9-8221-e442a6f8adc6\"}, {\"mode\": \"lines+markers\", \"name\": \"Mean Test Score\", \"x\": [2.0, 10.0, 25.0, 50.0, 100.0, 150.0], \"y\": [0.44213819449742653, 0.4518551455961089, 0.45483738272274193, 0.45932204001794746, 0.4625254548949771, 0.4590757909579968], \"yaxis\": \"y2\", \"type\": \"scattergl\", \"uid\": \"783bd959-ab6e-11e9-9f6f-e442a6f8adc6\"}],\n",
       "            {\"legend\": {\"orientation\": \"h\", \"y\": 1.12}, \"margin\": {\"t\": 120}, \"title\": \"Model Train+Test Time & Test Score vs max_features\", \"xaxis\": {\"title\": \"max_features\"}, \"yaxis\": {\"title\": \"Combined Train+Test Time\"}, \"yaxis2\": {\"side\": \"right\", \"title\": \"Mean Test Score\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('0a42e936-98a7-420e-8fbc-dc87f791750a',{});}).then(function(){Plotly.animate('0a42e936-98a7-420e-8fbc-dc87f791750a');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cv(results, 'max_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### oob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.78 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:460: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:465: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid=True, n_jobs=-1, param_grid={'oob_score': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'oob_score': [True, False]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oob_score</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2.519834</td>\n",
       "      <td>0.453303</td>\n",
       "      <td>0.977412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2.538115</td>\n",
       "      <td>0.452112</td>\n",
       "      <td>0.977804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   oob_score  combined_mean_fit-test_time  mean_test_score  mean_train_score\n",
       "0       True                     2.519834         0.453303          0.977412\n",
       "1      False                     2.538115         0.452112          0.977804"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'oob_score': [True, False],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### warm_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid=True, n_jobs=-1, param_grid={'warm_start': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'warm_start': [True, False]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warm_start</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2.159243</td>\n",
       "      <td>0.455958</td>\n",
       "      <td>0.976786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2.663219</td>\n",
       "      <td>0.453240</td>\n",
       "      <td>0.977428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warm_start  combined_mean_fit-test_time  mean_test_score  mean_train_score\n",
       "0        True                     2.159243         0.455958          0.976786\n",
       "1       False                     2.663219         0.453240          0.977428"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'warm_start': [True, False],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, 'balanced',\n",
       "                                          'balanced_subsample']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'class_weight': [None, 'balanced', 'balanced_subsample']}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_weight</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4.673367</td>\n",
       "      <td>0.449082</td>\n",
       "      <td>0.977245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balanced</td>\n",
       "      <td>5.801716</td>\n",
       "      <td>0.456594</td>\n",
       "      <td>0.977850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>2.735734</td>\n",
       "      <td>0.454496</td>\n",
       "      <td>0.978093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class_weight  combined_mean_fit-test_time  mean_test_score  \\\n",
       "0                None                     4.673367         0.449082   \n",
       "1            balanced                     5.801716         0.456594   \n",
       "2  balanced_subsample                     2.735734         0.454496   \n",
       "\n",
       "   mean_train_score  \n",
       "0          0.977245  \n",
       "1          0.977850  \n",
       "2          0.978093  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'max_leaf_nodes': [None, 10, 25, 50, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'max_leaf_nodes': [None, 10, 25, 50, 100, 150]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>combined_mean_fit-test_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.672754</td>\n",
       "      <td>0.451088</td>\n",
       "      <td>0.977471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.443652</td>\n",
       "      <td>0.375279</td>\n",
       "      <td>0.385786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>3.029357</td>\n",
       "      <td>0.417575</td>\n",
       "      <td>0.443285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2.879910</td>\n",
       "      <td>0.446965</td>\n",
       "      <td>0.467245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>4.479641</td>\n",
       "      <td>0.457010</td>\n",
       "      <td>0.487207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150.0</td>\n",
       "      <td>4.730571</td>\n",
       "      <td>0.455460</td>\n",
       "      <td>0.494722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_leaf_nodes  combined_mean_fit-test_time  mean_test_score  \\\n",
       "0             NaN                     2.672754         0.451088   \n",
       "1            10.0                     2.443652         0.375279   \n",
       "2            25.0                     3.029357         0.417575   \n",
       "3            50.0                     2.879910         0.446965   \n",
       "4           100.0                     4.479641         0.457010   \n",
       "5           150.0                     4.730571         0.455460   \n",
       "\n",
       "   mean_train_score  \n",
       "0          0.977471  \n",
       "1          0.385786  \n",
       "2          0.443285  \n",
       "3          0.467245  \n",
       "4          0.487207  \n",
       "5          0.494722  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'max_leaf_nodes': [None, 10, 25, 50, 100, 150],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'user_2932'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-a810fc96a3b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \"\"\"\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    393\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'user_2932'"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, \n",
    "                             max_depth=50, \n",
    "                             min_samples_split=25, \n",
    "                             min_samples_leaf=25,\n",
    "                             max_features=50,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative & Content Filtering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique users\n",
    "n_u = submissions['user_id'].nunique()\n",
    "# number of unique items (problems)\n",
    "n_i = submissions['problem_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique users: %s' % n_u)\n",
    "print('Number of unique problems: %s' % n_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = len(submissions)/(n_u*n_i)\n",
    "print('Sparsity of attempts_range: %s%%' % round(sparsity*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full submissions dataset contains 3529 unique users and 5776 unique problems. We have attempts_range data for only 0.76% of all user x problem combinations!! This data is incredibly sparse. Even the Netflix prize dataset had over 1% ratings. This will likely make it much harder for collaborative filtering models to produce good results, as they depend on inferring the attempts_range from the other users and/or items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sampling we can pivot both R_train and R_cv into sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train = R_train.set_index(['user_id','problem_id']).unstack(level=-1)\n",
    "R_cv = R_cv.set_index(['user_id','problem_id']).unstack(level=-1)\n",
    "\n",
    "R_train.columns = R_train.columns.droplevel()\n",
    "R_cv.columns = R_cv.columns.droplevel()\n",
    "\n",
    "R_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will be building several types of models using very different types of methods to fill missing attempt_range values, I'll start by creating an empty matrix that contains all user_ids as the index and all problem ids as columns. This matrix is constructed using the full list of users and problems from the users and problems datasets and not the submissions dataset. This is because there are many users and problems for which we have meta data but no history of submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u_diff = len(set(users.user_id.unique()).difference(submissions.user_id.unique()))\n",
    "print('Number of users from users dataset, not present in submissions: %s' % u_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diff = len(set(problems.problem_id.unique()).difference(submissions.problem_id.unique()))\n",
    "print('Number of problems from problems dataset, not present in submissions: %s' % p_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "empty_sub = pd.DataFrame(np.nan, index=users.user_id.unique(), \n",
    "                         columns=problems.problem_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fill in the R_train and R_cv data into the empty_sub matrix to have all data and predictions in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_train = empty_sub.fillna(R_train)\n",
    "R_cv = empty_sub.fillna(R_cv)\n",
    "R_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we created a baseline model before building our random forest models by simply predicting 1 for all missing attempts_range. Let's start by doing the same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(R_train, np.ones((R_train.shape[0], R_train.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(R_cv, np.ones((R_cv.shape[0], R_cv.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a simimlar value as before, only slightly smaller since our sample is different than before. While we will be using the F1 score as the final metric to compare models, I will use root mean squared error (RMSE) to optimize the fit of our model to the training data. Below I define a function that calculates the RMSE between two matrices, one with the ground truth values and the second with the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(R_true, R_pred):\n",
    "    \"\"\"Calculate the RMSE between two matrices, one\n",
    "    containing the ground truth, and the other a\n",
    "    model's predictions\"\"\"\n",
    "    \n",
    "    # number of total, non-null samples\n",
    "    n = R_true.count().sum()\n",
    "    \n",
    "    # square of the residuals\n",
    "    res_squared = (R_true - R_pred)**2\n",
    "    \n",
    "    RMSE = np.sqrt(np.sum(np.sum(res_squared))/(n))\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the RMSE for a prediction of all ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred = np.ones((R_train.shape[0], R_train.shape[1]))\n",
    "rmse(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our baseline model of predicting all ones gives a starting F1_score of 0.371 and an RMSE of 1.31. Let's see how much we can improve on this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-mean Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first type of collaborative filtering model I'll build is a user-mean collaborative filtering model. This simple model fills all missing attempts_range values with the averages across all users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a method for dealing with edge cases where we may not have data to make a prediction. For example, since we'll be calculating the mean of each problem and using that to make predictions for all users, we could have problems that were never solved in the training data and therefore not have any predictions made for those columns. Then, in the CV and test datasets, those columns could have data that should've been predicted on. The easiest way to deal with this is to simply predict 1 when we don't have data, since this is by far the most common value of attempts_range across all problems and users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute the mean of each problem across all users\n",
    "# round to nearest int\n",
    "user_means = np.round(R_train.mean())\n",
    "\n",
    "# fill the empty_sub for scoring\n",
    "R_pred = empty_sub.fillna(user_means)\n",
    "\n",
    "# fill all missing values with 1\n",
    "R_pred = R_pred.fillna(1)\n",
    "\n",
    "R_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this simple model produces an F1 score that's much better than the baseline, but still worse than our best random forest model. Let's see how this compares to item-based collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-mean Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_means = np.round(R_train.mean(axis=1))\n",
    "\n",
    "R_pred = empty_sub.T.fillna(problem_means).T\n",
    "\n",
    "R_pred = R_pred.fillna(1)\n",
    "R_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Item-based Collaborative filtering model does considerably worse than the user-based model. In fact, this does worse than even our baseline model where we predicted 1 for all missing attempts_ranges! Here we get an F1 score of 0.34 whereas the baseline model was 0.37."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-based vs Item-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(attempts, kind='user', epsilon=1e-9):\n",
    "    # fill all NaN values with 0. This does not affect\n",
    "    # the cosine similarity metric.\n",
    "    attempts = np.nan_to_num(attempts, 0)\n",
    "    \n",
    "    # compute the dot product between each user\n",
    "    # and all other users.\n",
    "    if kind == 'user':\n",
    "        sim = np.dot(attempts, attempts.T) + epsilon\n",
    "    # compute the dot product between each item\n",
    "    # and all other items\n",
    "    if kind == 'item':\n",
    "        sim = np.dot(attempts.T, attempts) + epsilon\n",
    "    \n",
    "    # compute the denominator of the cosine similarity\n",
    "    # metric\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    \n",
    "    # the dimensions of the returned matrix is \n",
    "    # userxuser.\n",
    "    return sim/norms/norms.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity_u = cos_sim(R_train, kind='user')\n",
    "similarity_i = cos_sim(R_train, kind='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(attempts, similarity, kind='user'):\n",
    "    # fill NaN values with 0\n",
    "    attempts_fill = np.nan_to_num(attempts, 0)\n",
    "    \n",
    "    if kind == 'user':\n",
    "        return np.round(similarity.dot(attempts_fill) / np.array([np.abs(similarity).sum(axis=1)]).T)\n",
    "    elif kind == 'item':\n",
    "        return np.round(attempts_fill.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_pred = predict(R_train, similarity_u, kind='user')\n",
    "f1(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_pred = predict(R_train, similarity_i, kind='item')\n",
    "f1(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the similarity of users and items using the features datasets rather than the attempt_ranges themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_norm = users.set_index('user_id')/users.set_index('user_id').max()\n",
    "user_features_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_pred = predict(R_train, cos_sim(user_features_norm))\n",
    "f1(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_features_norm = problems.set_index('problem_id')/problems.set_index('problem_id').max()\n",
    "problem_features_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred = predict(R_train, cos_sim(problem_features_norm), kind='item')\n",
    "f1(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Factor Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll(P, Q, order='C'):\n",
    "    \"\"\"Flatten two matrices and stack them on\n",
    "    top of each other in a single array.\"\"\"\n",
    "    P = np.array(P)\n",
    "    Q = np.array(Q)\n",
    "\n",
    "    x = np.concatenate((P.flatten(order=order),\n",
    "                        Q.flatten(order=order)), axis=0)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(x, n_u, n_i, f):\n",
    "    \"\"\"Reshape a single array into the two\n",
    "    original matrices.\"\"\"\n",
    "    \n",
    "    P = np.reshape(x[0:n_u*f], (n_u, f))\n",
    "    Q = np.reshape(x[n_u*f:], (n_i, f))\n",
    "\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_f(x, y, L, n_u, n_i, f):\n",
    "    P, Q = roll(x, n_u, n_i, f)\n",
    "\n",
    "    hyp = np.dot(P, Q.T)\n",
    "    error = hyp - y\n",
    "    error[np.isnan(error)] = 0 # Sets all missing values to 0s\n",
    "\n",
    "    # Compute the COST FUNCTION with REGULARIZATION\n",
    "    Q_reg = (L/2) * np.nansum(Q*Q)\n",
    "    P_reg = (L/2) * np.nansum(P*P)\n",
    "\n",
    "    J = (1/2) * np.nansum(error*error) + Q_reg + P_reg\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_f(x, y, L, n_u, n_i, f):\n",
    "    P, Q = roll(x, n_u, n_i, f)\n",
    "\n",
    "    hyp = np.dot(P, Q.T)\n",
    "    error = hyp - y\n",
    "    error[np.isnan(error)] = 0 # Sets all missing values to 0s\n",
    "\n",
    "    P_grad = np.dot(error, Q) + L*P\n",
    "    Q_grad = np.dot(error.T, P) + L*Q\n",
    "\n",
    "    grad = unroll(P_grad, Q_grad)\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_u = R_train.shape[0] # number of users\n",
    "n_i = R_train.shape[1] # number of items\n",
    "f = 10 # number of latent factors\n",
    "L=1 # regularization parameter\n",
    "\n",
    "# intial random guess at P & Q\n",
    "P0 = np.random.rand(n_u, f) - 0.5\n",
    "Q0 = np.random.rand(n_i, f) - 0.5\n",
    "\n",
    "x0 = unroll(P0, Q0)\n",
    "\n",
    "cost_f(x0, y=R_train, L=1, n_u=n_u, n_i=n_i, f=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "args = (R_train, L, n_u, n_i, f)\n",
    "options={'maxiter':2, 'disp':True}\n",
    "\n",
    "result = minimize(cost_f, x0, args=args, jac=grad_f, method='CG', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover P & Q matrices\n",
    "P, Q = roll(result.x, n_u, n_i, f)\n",
    "\n",
    "# compute predictions from P & Q\n",
    "R_pred = pd.DataFrame(np.dot(P, Q.T), index=R_train.index, columns=R_train.columns)\n",
    "\n",
    "# set all negative predictions to 1 (bottom limit)\n",
    "R_pred[R_pred < 0] = 1\n",
    "\n",
    "# round all values\n",
    "R_pred = round(R_pred)\n",
    "\n",
    "R_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "args = (R_train, L, n_u, n_i, f)\n",
    "options={'maxiter':5, 'disp':True}\n",
    "\n",
    "optimizers = ['CG','Newton-CG','L-BFGS-B']\n",
    "\n",
    "results = {}\n",
    "for optimizer in optimizers:\n",
    "    t0=time.time()\n",
    "    result = minimize(cost_f, x0, args=args, jac=grad_f, method=optimizer, options=options)\n",
    "    training_time=time.time()-t0\n",
    "    results[optimizer] = {'result':result, 'training_time':training_time}\n",
    "    print('Training time: %s seconds' % round(training_time,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['L-BFGS-B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "options={'maxiter':10, 'disp':True}\n",
    "\n",
    "result = minimize(cost_f, x0, args=args, jac=grad_f, method='Newton-CG', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover P & Q matrices\n",
    "P, Q = roll(result.x, n_u, n_i, f)\n",
    "\n",
    "# compute predictions from P & Q\n",
    "R_pred = pd.DataFrame(np.dot(P, Q.T), index=R_train.index, columns=R_train.columns)\n",
    "\n",
    "# set all negative predictions to 1 (bottom limit)\n",
    "R_pred[R_pred < 0] = 1\n",
    "\n",
    "# round all values\n",
    "R_pred = round(R_pred)\n",
    "\n",
    "f1(R_train, R_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(R_cv, R_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
