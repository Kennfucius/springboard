{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 1: In-Depth Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kenneth Liao\n",
    "\n",
    "Original datasource: https://datahack.analyticsvidhya.com/contest/practice-problem-recommendation-engine/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import minimize, fmin_cg\n",
    "\n",
    "# enable offline plotting in plotly\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('results/'+ name + '.pkl', 'wb') as f:\n",
    "        pkl.dump(obj, f, pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('results/' + name + '.pkl', 'rb') as f:\n",
    "        return pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our 3 datasets\n",
    "users = pd.read_csv('data/user_features.csv')\n",
    "problems =  pd.read_csv('data/problem_features.csv')\n",
    "submissions = pd.read_csv('data/train_submissions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background & Problem Statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, the goal of this project is to recommend practice problems to users given some information about the problems they have already solved. There are many criteria we could choose to base how we recommend problems. For the purpose of this model, I will keep the criteria simple. The criteria are as follows:\n",
    "\n",
    "1. The problem has not yet been attempted by the user.\n",
    "2. The predicted number of attempts the user will require to solve the problem is equal to 2 or 3 (attempts_range=2).\n",
    "\n",
    "Given the criteria defined above, we must first be able to predict how many attempts a user will require to solve a problem they've never attempted before. I will perform this prediction using two very different models. \n",
    "\n",
    "The first model will be a Random Forest Classifier. For this model, I will use meta data available for users and problems. The goal is to find patterns in the user and problem features that predict well the number of attempts for a given user-problem combination.\n",
    "\n",
    "The second model will be a collaborative filtering model. This model will employ stochastic gradient descent (SGD) to find an approximate solution to the single value decomposition (SVD) of our user-problem matrix. In this case, we will not utilize the user and problem datasets. Predictions will be made exclusively using the history of problem submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the submissions dataset. This dataset has 3 columns: user_id, problem_id, and attempts_range. Attempts_range gives the range of attempts that the user_id took to solve the problem_id and is defined in the original datasource as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>attempts_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_232</td>\n",
       "      <td>prob_6507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_3568</td>\n",
       "      <td>prob_2994</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_1600</td>\n",
       "      <td>prob_5071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_2256</td>\n",
       "      <td>prob_703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_2321</td>\n",
       "      <td>prob_356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id problem_id  attempts_range\n",
       "0   user_232  prob_6507               1\n",
       "1  user_3568  prob_2994               3\n",
       "2  user_1600  prob_5071               1\n",
       "3  user_2256   prob_703               1\n",
       "4  user_2321   prob_356               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We have used following criteria to define the attempts_range :-\n",
    ">\n",
    ">            attempts_range            No. of attempts lies inside\n",
    ">\n",
    ">            1                                         1-1\n",
    ">\n",
    ">            2                                         2-3\n",
    ">\n",
    ">            3                                         4-5\n",
    ">\n",
    ">            4                                         6-7\n",
    ">\n",
    ">            5                                         8-9\n",
    ">\n",
    ">            6                                         >=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do to prepare the data for the random forest model is convert categorical, string columns into dummy variables. We do this for both the user and problem features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>submission_count</th>\n",
       "      <th>problem_solved</th>\n",
       "      <th>contribution</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>last_online_time_seconds</th>\n",
       "      <th>max_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>registration_time_seconds</th>\n",
       "      <th>user_attempts_median</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Ukraine</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States</th>\n",
       "      <th>country_Uzbekistan</th>\n",
       "      <th>country_Venezuela</th>\n",
       "      <th>country_Vietnam</th>\n",
       "      <th>rank_advanced</th>\n",
       "      <th>rank_beginner</th>\n",
       "      <th>rank_expert</th>\n",
       "      <th>rank_intermediate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>84</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1505162220</td>\n",
       "      <td>502.007</td>\n",
       "      <td>499.713</td>\n",
       "      <td>1469108674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_10</td>\n",
       "      <td>246</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1505079658</td>\n",
       "      <td>326.548</td>\n",
       "      <td>313.360</td>\n",
       "      <td>1472038187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_100</td>\n",
       "      <td>642</td>\n",
       "      <td>574</td>\n",
       "      <td>27</td>\n",
       "      <td>106</td>\n",
       "      <td>1505073569</td>\n",
       "      <td>458.429</td>\n",
       "      <td>385.894</td>\n",
       "      <td>1323974332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1000</td>\n",
       "      <td>259</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1505579889</td>\n",
       "      <td>371.273</td>\n",
       "      <td>336.583</td>\n",
       "      <td>1450375392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_1001</td>\n",
       "      <td>554</td>\n",
       "      <td>492</td>\n",
       "      <td>-6</td>\n",
       "      <td>55</td>\n",
       "      <td>1504521879</td>\n",
       "      <td>472.190</td>\n",
       "      <td>450.975</td>\n",
       "      <td>1423399585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  submission_count  problem_solved  contribution  follower_count  \\\n",
       "0     user_1                84              73            10             120   \n",
       "1    user_10               246             211             0              30   \n",
       "2   user_100               642             574            27             106   \n",
       "3  user_1000               259             235             0              41   \n",
       "4  user_1001               554             492            -6              55   \n",
       "\n",
       "   last_online_time_seconds  max_rating   rating  registration_time_seconds  \\\n",
       "0                1505162220     502.007  499.713                 1469108674   \n",
       "1                1505079658     326.548  313.360                 1472038187   \n",
       "2                1505073569     458.429  385.894                 1323974332   \n",
       "3                1505579889     371.273  336.583                 1450375392   \n",
       "4                1504521879     472.190  450.975                 1423399585   \n",
       "\n",
       "   user_attempts_median  ...  country_Ukraine  country_United Kingdom  \\\n",
       "0                   1.0  ...                0                       0   \n",
       "1                   1.0  ...                0                       0   \n",
       "2                   1.0  ...                0                       0   \n",
       "3                   1.0  ...                0                       0   \n",
       "4                   1.0  ...                0                       0   \n",
       "\n",
       "   country_United States  country_Uzbekistan  country_Venezuela  \\\n",
       "0                      0                   0                  0   \n",
       "1                      0                   0                  0   \n",
       "2                      0                   0                  0   \n",
       "3                      0                   0                  0   \n",
       "4                      0                   0                  0   \n",
       "\n",
       "   country_Vietnam  rank_advanced  rank_beginner  rank_expert  \\\n",
       "0                0              1              0            0   \n",
       "1                0              0              0            0   \n",
       "2                0              0              0            0   \n",
       "3                0              0              0            0   \n",
       "4                0              0              0            0   \n",
       "\n",
       "   rank_intermediate  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.get_dummies(users.set_index('user_id')).reset_index()\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>points</th>\n",
       "      <th>problem_attempts_median</th>\n",
       "      <th>problem_attempts_min</th>\n",
       "      <th>problem_attempts_max</th>\n",
       "      <th>problem_attempts_count</th>\n",
       "      <th>problem_attempts_iqr</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>and</th>\n",
       "      <th>binary</th>\n",
       "      <th>...</th>\n",
       "      <th>level_type_E</th>\n",
       "      <th>level_type_F</th>\n",
       "      <th>level_type_G</th>\n",
       "      <th>level_type_H</th>\n",
       "      <th>level_type_I</th>\n",
       "      <th>level_type_J</th>\n",
       "      <th>level_type_K</th>\n",
       "      <th>level_type_L</th>\n",
       "      <th>level_type_M</th>\n",
       "      <th>level_type_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prob_1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prob_10</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prob_100</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prob_1000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prob_1001</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  problem_id  points  problem_attempts_median  problem_attempts_min  \\\n",
       "0     prob_1   500.0                      1.5                   1.0   \n",
       "1    prob_10  4500.0                      6.0                   6.0   \n",
       "2   prob_100  1000.0                      1.0                   1.0   \n",
       "3  prob_1000   500.0                      1.0                   1.0   \n",
       "4  prob_1001  2000.0                      1.0                   1.0   \n",
       "\n",
       "   problem_attempts_max  problem_attempts_count  problem_attempts_iqr  \\\n",
       "0                   2.0                     2.0                 0.005   \n",
       "1                   6.0                     1.0                 0.000   \n",
       "2                   1.0                     1.0                 0.000   \n",
       "3                   6.0                   246.0                 0.000   \n",
       "4                   2.0                    10.0                 0.000   \n",
       "\n",
       "   algorithms  and  binary  ...  level_type_E  level_type_F  level_type_G  \\\n",
       "0           0    0       0  ...             0             0             0   \n",
       "1           0    0       0  ...             0             0             0   \n",
       "2           0    0       0  ...             0             0             0   \n",
       "3           0    0       0  ...             0             0             0   \n",
       "4           0    0       0  ...             0             0             0   \n",
       "\n",
       "   level_type_H  level_type_I  level_type_J  level_type_K  level_type_L  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             1             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   level_type_M  level_type_N  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             0             0  \n",
       "4             0             0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems = pd.get_dummies(problems.set_index('problem_id')).reset_index()\n",
    "problems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by splitting the whole dataset into a train (X_train) and test (X_test) set. I'll further split the X_train data into a smaller training set (R_train) and a cross-validation set (R_cv) for hyperparameter tuning. This split must be done on the original submissions dataset before pivoting the data into a sparse matrix. Once in sparse matrix format, sampling the dataset would also sample the null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, R_test = train_test_split(submissions, test_size=0.25, random_state=42)\n",
    "\n",
    "R_train, R_cv = train_test_split(train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>attempts_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>user_3506</td>\n",
       "      <td>prob_3882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110245</th>\n",
       "      <td>user_1732</td>\n",
       "      <td>prob_3373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78649</th>\n",
       "      <td>user_2502</td>\n",
       "      <td>prob_2421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72195</th>\n",
       "      <td>user_2653</td>\n",
       "      <td>prob_6016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16731</th>\n",
       "      <td>user_1399</td>\n",
       "      <td>prob_6434</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id problem_id  attempts_range\n",
       "2573    user_3506  prob_3882               1\n",
       "110245  user_1732  prob_3373               1\n",
       "78649   user_2502  prob_2421               1\n",
       "72195   user_2653  prob_6016               1\n",
       "16731   user_1399  prob_6434               2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll prepare a single dataframe that joins the user and problem features with the submissions data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>submission_count</th>\n",
       "      <th>problem_solved</th>\n",
       "      <th>contribution</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>last_online_time_seconds</th>\n",
       "      <th>max_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>registration_time_seconds</th>\n",
       "      <th>user_attempts_median</th>\n",
       "      <th>user_attempts_min</th>\n",
       "      <th>...</th>\n",
       "      <th>level_type_E</th>\n",
       "      <th>level_type_F</th>\n",
       "      <th>level_type_G</th>\n",
       "      <th>level_type_H</th>\n",
       "      <th>level_type_I</th>\n",
       "      <th>level_type_J</th>\n",
       "      <th>level_type_K</th>\n",
       "      <th>level_type_L</th>\n",
       "      <th>level_type_M</th>\n",
       "      <th>level_type_N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_3506</th>\n",
       "      <th>prob_3882</th>\n",
       "      <td>107</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1501774775</td>\n",
       "      <td>305.333</td>\n",
       "      <td>302.466</td>\n",
       "      <td>1476642256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1669</th>\n",
       "      <th>prob_3882</th>\n",
       "      <td>430</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1504392528</td>\n",
       "      <td>340.310</td>\n",
       "      <td>314.220</td>\n",
       "      <td>1454321387</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_466</th>\n",
       "      <th>prob_3882</th>\n",
       "      <td>163</td>\n",
       "      <td>127</td>\n",
       "      <td>-4</td>\n",
       "      <td>8</td>\n",
       "      <td>1503050499</td>\n",
       "      <td>432.626</td>\n",
       "      <td>399.943</td>\n",
       "      <td>1461554180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_2661</th>\n",
       "      <th>prob_3882</th>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1505058916</td>\n",
       "      <td>315.367</td>\n",
       "      <td>260.894</td>\n",
       "      <td>1431933069</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1416</th>\n",
       "      <th>prob_3882</th>\n",
       "      <td>267</td>\n",
       "      <td>263</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "      <td>1502201891</td>\n",
       "      <td>308.200</td>\n",
       "      <td>227.924</td>\n",
       "      <td>1459617061</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      submission_count  problem_solved  contribution  \\\n",
       "user_id   problem_id                                                   \n",
       "user_3506 prob_3882                107              77             0   \n",
       "user_1669 prob_3882                430             392             0   \n",
       "user_466  prob_3882                163             127            -4   \n",
       "user_2661 prob_3882                 45              36             2   \n",
       "user_1416 prob_3882                267             263           -12   \n",
       "\n",
       "                      follower_count  last_online_time_seconds  max_rating  \\\n",
       "user_id   problem_id                                                         \n",
       "user_3506 prob_3882                0                1501774775     305.333   \n",
       "user_1669 prob_3882                4                1504392528     340.310   \n",
       "user_466  prob_3882                8                1503050499     432.626   \n",
       "user_2661 prob_3882                6                1505058916     315.367   \n",
       "user_1416 prob_3882                0                1502201891     308.200   \n",
       "\n",
       "                       rating  registration_time_seconds  \\\n",
       "user_id   problem_id                                       \n",
       "user_3506 prob_3882   302.466                 1476642256   \n",
       "user_1669 prob_3882   314.220                 1454321387   \n",
       "user_466  prob_3882   399.943                 1461554180   \n",
       "user_2661 prob_3882   260.894                 1431933069   \n",
       "user_1416 prob_3882   227.924                 1459617061   \n",
       "\n",
       "                      user_attempts_median  user_attempts_min  ...  \\\n",
       "user_id   problem_id                                           ...   \n",
       "user_3506 prob_3882                    1.0                1.0  ...   \n",
       "user_1669 prob_3882                    1.0                1.0  ...   \n",
       "user_466  prob_3882                    1.0                1.0  ...   \n",
       "user_2661 prob_3882                    1.5                1.0  ...   \n",
       "user_1416 prob_3882                    2.0                1.0  ...   \n",
       "\n",
       "                      level_type_E  level_type_F  level_type_G  level_type_H  \\\n",
       "user_id   problem_id                                                           \n",
       "user_3506 prob_3882              0             0             0             0   \n",
       "user_1669 prob_3882              0             0             0             0   \n",
       "user_466  prob_3882              0             0             0             0   \n",
       "user_2661 prob_3882              0             0             0             0   \n",
       "user_1416 prob_3882              0             0             0             0   \n",
       "\n",
       "                      level_type_I  level_type_J  level_type_K  level_type_L  \\\n",
       "user_id   problem_id                                                           \n",
       "user_3506 prob_3882              0             0             0             0   \n",
       "user_1669 prob_3882              0             0             0             0   \n",
       "user_466  prob_3882              0             0             0             0   \n",
       "user_2661 prob_3882              0             0             0             0   \n",
       "user_1416 prob_3882              0             0             0             0   \n",
       "\n",
       "                      level_type_M  level_type_N  \n",
       "user_id   problem_id                              \n",
       "user_3506 prob_3882              0             0  \n",
       "user_1669 prob_3882              0             0  \n",
       "user_466  prob_3882              0             0  \n",
       "user_2661 prob_3882              0             0  \n",
       "user_1416 prob_3882              0             0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = R_train.merge(users, on='user_id').merge(problems, on='problem_id')\n",
    "X_cv = R_cv.merge(users, on='user_id').merge(problems, on='problem_id')\n",
    "\n",
    "# remove rows with any null values\n",
    "X_train = X_train.loc[:,X_train.notnull().all()]\n",
    "X_cv = X_cv.loc[:,X_cv.notnull().all()]\n",
    "\n",
    "y_train = X_train.set_index(['user_id', 'problem_id'])['attempts_range']\n",
    "X_train = X_train.set_index(['user_id', 'problem_id']).loc[:,'submission_count':]\n",
    "\n",
    "y_cv = X_cv.set_index(['user_id', 'problem_id'])['attempts_range']\n",
    "X_cv = X_cv.set_index(['user_id', 'problem_id']).loc[:,'submission_count':]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    problem_id\n",
       "user_3506  prob_3882     1\n",
       "user_1669  prob_3882     1\n",
       "user_466   prob_3882     1\n",
       "user_2661  prob_3882     2\n",
       "user_1416  prob_3882     2\n",
       "Name: attempts_range, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe X now contains all of the user and problem feature data for each combination of user_id and problem_id. Thus, for each training sample or row, we will use the combination of user and problem features to predict the attempts_range. The attempts_range for each user-problem combination is saved in y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplest Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from our previous exploratory analysis of this data that 1 is by far the most common attempts_range. A very simple prediction model we can make is just to predict the most common value for all missing values. Let's see how such a model would do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To benchmark our models, we'll be using sklearn's f1_score function with the average argument set to \"weighted\". This function will compute the f1-score for each of the labels in the dataset and then take a weighted average of the scores depending on how many samples are in each label. Thus, we will simply get one overall f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(Y_true, Y_predicted, average='weighted'):\n",
    "    \"\"\"Compute the f1_score between actual values \n",
    "    and predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert matrices into numpy arrays\n",
    "    Y_true_ = np.array(Y_true)\n",
    "    Y_predicted_ = np.array(Y_predicted)\n",
    "    \n",
    "    # get indices of non-NaN values in Y_true\n",
    "    mask = ~np.isnan(Y_true_.flatten(order='C'))\n",
    "    \n",
    "    # flatten matrices to 1D arrays\n",
    "    # use the mask to get only non-NaN values\n",
    "    y_true = Y_true_.flatten(order='C')[mask]\n",
    "    y_predicted = Y_predicted_.flatten(order='C')[mask]\n",
    "    \n",
    "    return f1_score(y_true, y_predicted, average=average, labels=[1.0,2.0,3.0,4.0,5.0,6.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predicted = np.ones(len(y_train))\n",
    "\n",
    "print('F1 score for predicting all ones on training data: %s' % round(f1(y_train, y_predicted), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score we got for predicting 1 for all of the training samples is 0.371. How does this compare in the CV dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv = R_cv.set_index(['user_id', 'problem_id'])['attempts_range']\n",
    "\n",
    "y_predicted = np.ones(len(y_cv))\n",
    "print('F1 score for predicting all ones on cv data: %s' % round(f1(y_cv, y_predicted), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a similar f1 score for predicting all ones on the CV dataset. This is a good indication that there was minimal selection bias in our splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out-of-box Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by building an out-of-box model and try to improve it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=12)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = clf.predict(X_train)\n",
    "\n",
    "f1(y_train, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = clf.predict(X_cv)\n",
    "\n",
    "f1(y_cv, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The out-of-box random forest models gives an f1 score of 0.977 on the training data and 0.414 on the cross-validation data. This is already much better than the baseline model! But we're still far from 1. During my exploratory analysis of the data, it was clear that many features were correlated with one another. Before diving into model optimization through hyperparameter tuning, I want to see if removing some of this colinearity between features improves the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by performing PCA on the full dataset to see how many features we can safely remove. Performing PCA on the full dataset has two benefits.\n",
    "\n",
    "1. The dimensionality of the training data is reduced and therefore takes less computation to train the model on.\n",
    "2. Colinear features are removed. The principal components returned by PCA are all orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "\n",
    "x = list(range(1, len(pca.explained_variance_)+1))\n",
    "y = pca.explained_variance_\n",
    "\n",
    "trace0 = go.Scatter(x=x, y=y, mode='lines+markers')\n",
    "\n",
    "layout = go.Layout(title='Explained Variance vs # of Dimensions',\n",
    "                  xaxis=dict(title='# of Dimensions'),\n",
    "                  yaxis=dict(title='Explained Variance', type='log'))\n",
    "\n",
    "fig = go.Figure([trace0], layout)\n",
    "\n",
    "iplot(fig, filename='explained-var_vs_N-dimensions.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=[1,2,5,10,25,50,100]\n",
    "\n",
    "f1_scores = []\n",
    "for n in n_components:\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    \n",
    "    X_train_r = pca.fit_transform(X_train)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100, n_jobs=12)\n",
    "\n",
    "    clf.fit(X_train_r, y_train)\n",
    "\n",
    "    y_predicted = clf.predict(X_train_r)\n",
    "\n",
    "    f1_scores.append(f1(y_train, y_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Scatter(x=n_components, y=f1_scores, mode='lines+markers')\n",
    "\n",
    "layout = go.Layout(title='F1 Score vs Principal Components',\n",
    "                  xaxis=dict(title='Principal Components'),\n",
    "                  yaxis=dict(title='F1 Score', type='log'))\n",
    "\n",
    "fig = go.Figure([trace0], layout)\n",
    "\n",
    "iplot(fig, filename='f1_score-vs-principal_components.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that at a number of principal components less than 25, there is a significant hit in the F1 score. Above 25 principal components, there seems to be a negligible difference. In general, there is no improvement over the baseline model when using PCA to remove colinear features and reduce the dataset's dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use GridSearhCV to try to tune the hyperparameters of the model. Rather than passing a large dictionary object of all the hyperparameters we want to tune at once, I will explore each of the hyperparameters individually. This will make it more straightforward when interpretting the effects of each hyperparameter. At the end, I will then pass all of the hyperparameters to GridSearchCV to find the optimal combination of all hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators defines how many trees the model will have. Generally, the more trees the better the model will generalize. However more trees equals more computation and therefore we want to strike a balance between fit to the test data and train + test times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With GridSearchCV, we can define the scoring function. Since we want to maximize the f1_score function with \"weighted\" averaging from sklearn.metrics, we pass this same scoring function to GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'n_estimators': [5,10,50,100,150,200,250]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the search are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'n_estimators' : [5,10,50,100,150,200,250],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the train and test scores as a function of N_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace2 = go.Scattergl(name='Mean Test Score',\n",
    "                      x=results['n_estimators'],\n",
    "                      y=results['mean_test_score'], \n",
    "                      mode='lines+markers',\n",
    "                     yaxis='y2')\n",
    "trace1 = go.Scattergl(name='Mean Train Score',\n",
    "                      x=results['n_estimators'],\n",
    "                      y=results['mean_train_score'], \n",
    "                      mode='lines+markers')\n",
    "\n",
    "layout = go.Layout(title='Mean Train & Test Scores vs N_estimators',\n",
    "               xaxis=dict(title='N_estimators'),\n",
    "               yaxis=dict(title='Mean Train Score'), \n",
    "                   yaxis2=dict(title='Mean Test Score',\n",
    "                              side='right'),\n",
    "                  legend=dict(orientation='h', y=1.12),\n",
    "                  margin=dict(t=120))\n",
    "\n",
    "fig = go.Figure([trace1, trace2], layout=layout)\n",
    "\n",
    "iplot(fig, filename='train-test-scores.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see both scores increase in going from 5 to 100 estimators but quickly plateau after that. The train and test scores are plotted on separate axes above so we can distinguish the knees of both curves. We can see that the training score is very close to 1, even for n_estimators=5. The more important score of course is the test score. Let's now look at the tradeoff between the test score and the time required to train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv(df, param):\n",
    "    trace0 = go.Scattergl(name='Combined Mean Train+Test Time',\n",
    "                      x=results[param],\n",
    "                      y=results['combined_mean_fit-test_time'], \n",
    "                      mode='lines+markers',)\n",
    "    trace1 = go.Scattergl(name='Mean Test Score',\n",
    "                          x=results[param],\n",
    "                          y=results['mean_test_score'], \n",
    "                          mode='lines+markers',\n",
    "                         yaxis='y2')\n",
    "\n",
    "    layout = go.Layout(title='Model Train+Test Time & Test Score vs %s' % param,\n",
    "                   xaxis=dict(title=param),\n",
    "                   yaxis=dict(title='Combined Train+Test Time'), \n",
    "                       yaxis2=dict(title='Mean Test Score',\n",
    "                                  side='right'),\n",
    "                      legend=dict(orientation='h', y=1.12),\n",
    "                      margin=dict(t=120))\n",
    "\n",
    "    fig = go.Figure([trace0, trace1], layout=layout)\n",
    "\n",
    "    iplot(fig, filename='%s.html' % param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cv(results, param='n_estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the combined time for training and testing the model increases significantly up to 109 seconds at N_estimators=150. At N_estimators=100, the train+test time is 65 seconds but the difference in test score between the two is negligible. We can thus save a lot of computational resources and time by choosing N_estimators=100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vals = np.arange(5,100,5)\n",
    "param_grid = {'max_depth': vals}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'max_depth' : vals,\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv(results, param='max_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vals = np.arange(10,300,10)\n",
    "param_grid = {'min_samples_split': vals}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'min_samples_split' : vals,\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv(results, param='min_samples_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vals = np.arange(5,100,5)\n",
    "param_grid = {'min_samples_leaf': vals}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'min_samples_leaf' : vals,\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv(results, param='min_samples_leaf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'criterion': [\"gini\", \"entropy\"]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'criterion' : ['gini', 'entropy'],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vals = np.arange(5,150,10)\n",
    "param_grid = {'max_features': vals}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'max_features': vals,\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv(results, 'max_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### oob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'oob_score': [True, False]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'oob_score': [True, False],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### warm_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'warm_start': [True, False]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'warm_start': [True, False],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'class_weight': [None, 'balanced', 'balanced_subsample']}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'max_leaf_nodes': [None, 10, 25, 50, 100, 150]}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=12)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'max_leaf_nodes': [None, 10, 25, 50, 100, 150],\n",
    "                        'combined_mean_fit-test_time': cv.cv_results_['mean_fit_time'] + cv.cv_results_['mean_score_time'],\n",
    "                        'mean_test_score': cv.cv_results_['mean_test_score'],\n",
    "                       'mean_train_score': cv.cv_results_['mean_train_score']})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'n_estimators': np.arange(10,200,10),\n",
    "             'max_depth': np.arange(5,40,5),\n",
    "             'min_samples_split': np.arange(5,40,5),\n",
    "             'max_features': np.arange(10,100,10)}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "cv = GridSearchCV(clf, param_grid=param_grid, \n",
    "                  scoring='f1_weighted', cv=5, \n",
    "                  iid=True, n_jobs=-1, \n",
    "                  return_train_score=True)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative & Content Filtering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_matrix(Y_true, Y_predicted, average='weighted', labels=[1.0,2.0,3.0,4.0,5.0,6.0]):\n",
    "    \n",
    "    \"\"\"Compute the f1_score between an actual values\n",
    "    matrix and predicted values matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Y_true : 2D numpy array\n",
    "        Matrix of true values.\n",
    "    Y_predicted : 2D numpy array\n",
    "        Matrix of predictions.\n",
    "    average : str\n",
    "        Method for weighting f1-score which is computed\n",
    "        for each label.\n",
    "    labels : list\n",
    "        List of labels to compute f1-scores over.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    f1 : float\n",
    "        f1-score computed using `average` method \n",
    "        across specified `labels`.\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_true_ = np.array(Y_true)\n",
    "    Y_predicted_ = np.array(Y_predicted)\n",
    "    \n",
    "    # get indices of non-NaN values\n",
    "    mask = ~np.isnan(Y_true_)\n",
    "    \n",
    "    # flatten mask into 1D array\n",
    "    mask = mask.flatten(order='C')\n",
    "    \n",
    "    # flatten matrices into 1D arrays\n",
    "    y_true = Y_true_.flatten(order='C')\n",
    "    y_predicted = Y_predicted_.flatten(order='C')\n",
    "    \n",
    "    # filter the arrays using the mask\n",
    "    y_true = y_true[mask]\n",
    "    y_predicted = y_predicted[mask]\n",
    "    \n",
    "    # compute f1-score\n",
    "    f1 = f1_score(y_true, y_predicted, average=average, labels=labels)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique users\n",
    "n_users = submissions['user_id'].nunique()\n",
    "# number of unique items (problems)\n",
    "n_items = submissions['problem_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 3529\n",
      "Number of unique problems: 5776\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique users: %s' % n_users)\n",
    "print('Number of unique problems: %s' % n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of attempts_range: 0.76%\n"
     ]
    }
   ],
   "source": [
    "sparsity = len(submissions)/(n_users*n_items)\n",
    "print('Sparsity of attempts_range: %s%%' % round(sparsity*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full submissions dataset contains 3529 unique users and 5776 unique problems. We have attempts_range data for only 0.76% of all user x problem combinations!! This data is incredibly sparse. Even the Netflix prize dataset had over 1% ratings. This will likely make it much harder for collaborative filtering models to produce good results, as they depend on inferring the attempts_range from the other users and/or items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sampling we can pivot both R_train and R_cv into sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>problem_id</th>\n",
       "      <th>prob_100</th>\n",
       "      <th>prob_1000</th>\n",
       "      <th>prob_1001</th>\n",
       "      <th>prob_1002</th>\n",
       "      <th>prob_1003</th>\n",
       "      <th>prob_1004</th>\n",
       "      <th>prob_1005</th>\n",
       "      <th>prob_1006</th>\n",
       "      <th>prob_1007</th>\n",
       "      <th>prob_101</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_989</th>\n",
       "      <th>prob_99</th>\n",
       "      <th>prob_991</th>\n",
       "      <th>prob_992</th>\n",
       "      <th>prob_994</th>\n",
       "      <th>prob_995</th>\n",
       "      <th>prob_996</th>\n",
       "      <th>prob_997</th>\n",
       "      <th>prob_998</th>\n",
       "      <th>prob_999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "problem_id  prob_100  prob_1000  prob_1001  prob_1002  prob_1003  prob_1004  \\\n",
       "user_id                                                                       \n",
       "user_1           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "user_10          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "user_100         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "user_1000        NaN        1.0        NaN        NaN        NaN        NaN   \n",
       "user_1001        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "problem_id  prob_1005  prob_1006  prob_1007  prob_101  ...  prob_989  prob_99  \\\n",
       "user_id                                                ...                      \n",
       "user_1            NaN        NaN        NaN       NaN  ...       NaN      NaN   \n",
       "user_10           NaN        NaN        NaN       NaN  ...       NaN      NaN   \n",
       "user_100          NaN        NaN        NaN       NaN  ...       NaN      NaN   \n",
       "user_1000         NaN        NaN        NaN       NaN  ...       NaN      NaN   \n",
       "user_1001         NaN        NaN        NaN       NaN  ...       NaN      NaN   \n",
       "\n",
       "problem_id  prob_991  prob_992  prob_994  prob_995  prob_996  prob_997  \\\n",
       "user_id                                                                  \n",
       "user_1           NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_10          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_100         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_1000        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_1001        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "problem_id  prob_998  prob_999  \n",
       "user_id                         \n",
       "user_1           NaN       NaN  \n",
       "user_10          NaN       NaN  \n",
       "user_100         NaN       NaN  \n",
       "user_1000        NaN       NaN  \n",
       "user_1001        NaN       NaN  \n",
       "\n",
       "[5 rows x 5004 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train = R_train.set_index(['user_id','problem_id']).unstack(level=-1)\n",
    "R_cv = R_cv.set_index(['user_id','problem_id']).unstack(level=-1)\n",
    "\n",
    "R_train.columns = R_train.columns.droplevel()\n",
    "R_cv.columns = R_cv.columns.droplevel()\n",
    "\n",
    "R_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will be building several types of models using very different types of methods to fill missing attempt_range values, I'll start by creating an empty matrix that contains all user_ids as the index and all problem ids as columns. This matrix is constructed using the full list of users and problems from the users and problems datasets and not the submissions dataset. This is because there are many users and problems for which we have meta data but no history of submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users from users dataset, not present in submissions: 42\n"
     ]
    }
   ],
   "source": [
    "u_diff = len(set(users.user_id.unique()).difference(submissions.user_id.unique()))\n",
    "print('Number of users from users dataset, not present in submissions: %s' % u_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of problems from problems dataset, not present in submissions: 768\n"
     ]
    }
   ],
   "source": [
    "p_diff = len(set(problems.problem_id.unique()).difference(submissions.problem_id.unique()))\n",
    "print('Number of problems from problems dataset, not present in submissions: %s' % p_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "empty_sub = pd.DataFrame(np.nan, index=users.user_id.unique(), \n",
    "                         columns=problems.problem_id.unique())\n",
    "empty_sub_ = np.array(empty_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fill in the R_train and R_cv data into the empty_sub matrix to have all data and predictions in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_10</th>\n",
       "      <th>prob_100</th>\n",
       "      <th>prob_1000</th>\n",
       "      <th>prob_1001</th>\n",
       "      <th>prob_1002</th>\n",
       "      <th>prob_1003</th>\n",
       "      <th>prob_1004</th>\n",
       "      <th>prob_1005</th>\n",
       "      <th>prob_1006</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_990</th>\n",
       "      <th>prob_991</th>\n",
       "      <th>prob_992</th>\n",
       "      <th>prob_993</th>\n",
       "      <th>prob_994</th>\n",
       "      <th>prob_995</th>\n",
       "      <th>prob_996</th>\n",
       "      <th>prob_997</th>\n",
       "      <th>prob_998</th>\n",
       "      <th>prob_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           prob_1  prob_10  prob_100  prob_1000  prob_1001  prob_1002  \\\n",
       "user_1        NaN      NaN       NaN        NaN        NaN        NaN   \n",
       "user_10       NaN      NaN       NaN        NaN        NaN        NaN   \n",
       "user_100      NaN      NaN       NaN        NaN        NaN        NaN   \n",
       "user_1000     NaN      NaN       NaN        1.0        NaN        NaN   \n",
       "user_1001     NaN      NaN       NaN        NaN        NaN        NaN   \n",
       "\n",
       "           prob_1003  prob_1004  prob_1005  prob_1006  ...  prob_990  \\\n",
       "user_1           NaN        NaN        NaN        NaN  ...       NaN   \n",
       "user_10          NaN        NaN        NaN        NaN  ...       NaN   \n",
       "user_100         NaN        NaN        NaN        NaN  ...       NaN   \n",
       "user_1000        NaN        NaN        NaN        NaN  ...       NaN   \n",
       "user_1001        NaN        NaN        NaN        NaN  ...       NaN   \n",
       "\n",
       "           prob_991  prob_992  prob_993  prob_994  prob_995  prob_996  \\\n",
       "user_1          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_10         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_100        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_1000       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_1001       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "           prob_997  prob_998  prob_999  \n",
       "user_1          NaN       NaN       NaN  \n",
       "user_10         NaN       NaN       NaN  \n",
       "user_100        NaN       NaN       NaN  \n",
       "user_1000       NaN       NaN       NaN  \n",
       "user_1001       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 6544 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train = empty_sub.fillna(R_train)\n",
    "R_cv = empty_sub.fillna(R_cv)\n",
    "\n",
    "R_train_ = np.array(R_train)\n",
    "R_cv_ = np.array(R_cv)\n",
    "\n",
    "R_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we created a baseline model before building our random forest models by simply predicting 1 for all missing attempts_range. Let's start by doing the same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3704453520558025"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_matrix(R_train_, np.ones((R_train_.shape[0], R_train_.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3721755273659568"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_matrix(R_cv_, np.ones((R_cv_.shape[0], R_cv_.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our baseline model of predicting all ones gives a starting F1_score of 0.370 on the training data and 0.372 on the cross-validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-mean Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first type of collaborative filtering model I'll build is a user-mean collaborative filtering model. This simple model fills all missing attempts_range values with the averages across all users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a method for dealing with edge cases where we may not have data to make a prediction. For example, since we'll be calculating the mean of each problem and using that to make predictions for all users, we could have problems that were never solved in the training data and therefore not have any predictions made for those columns. Then, in the CV and test datasets, those columns could have data that should've been predicted on. The easiest way to deal with this is to simply predict 1 when we don't have data, since this is by far the most common value of attempts_range across all problems and users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute the mean of each problem across all users\n",
    "# round to nearest int\n",
    "user_means = np.round(R_train.mean())\n",
    "\n",
    "# fill the empty_sub for scoring\n",
    "R_predicted = empty_sub.fillna(user_means)\n",
    "\n",
    "# fill all missing values with 1\n",
    "R_predicted = R_predicted.fillna(1)\n",
    "\n",
    "R_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_matrix(R_train, R_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this simple model produces an F1 score that's much better than the baseline, but still worse than our best random forest model. Let's see how this compares to item-based collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-mean Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_means = np.round(R_train.mean(axis=1))\n",
    "\n",
    "R_predicted = empty_sub.T.fillna(problem_means).T\n",
    "\n",
    "R_predicted = R_predicted.fillna(1)\n",
    "\n",
    "R_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_matrix(R_train, R_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Item-based Collaborative filtering model does considerably worse than the user-based model. In fact, this does worse than even our baseline model where we predicted 1 for all missing attempts_ranges! Here we get an F1 score of 0.34 whereas the baseline model was 0.37."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-based vs Item-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(attempts, kind='user', epsilon=1e-9):\n",
    "    # fill all NaN values with 0. This does not affect\n",
    "    # the cosine similarity metric.\n",
    "    attempts = np.nan_to_num(attempts, 0)\n",
    "    \n",
    "    # compute the dot product between each user\n",
    "    # and all other users.\n",
    "    if kind == 'user':\n",
    "        sim = np.dot(attempts, attempts.T) + epsilon\n",
    "    # compute the dot product between each item\n",
    "    # and all other items\n",
    "    if kind == 'item':\n",
    "        sim = np.dot(attempts.T, attempts) + epsilon\n",
    "    \n",
    "    # compute the denominator of the cosine similarity\n",
    "    # metric\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    \n",
    "    # the dimensions of the returned matrix is \n",
    "    # userxuser.\n",
    "    return sim/norms/norms.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity_users = cos_sim(R_train_, kind='user')\n",
    "similarity_items = cos_sim(R_train_, kind='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(attempts, similarity, kind='user'):\n",
    "    # fill NaN values with 0\n",
    "    attempts_fill = np.nan_to_num(attempts, 0)\n",
    "    \n",
    "    if kind == 'user':\n",
    "        return np.round(similarity.dot(attempts_fill) / np.array([np.abs(similarity).sum(axis=1)]).T)\n",
    "    elif kind == 'item':\n",
    "        return np.round(attempts_fill.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_predicted = predict(R_train, similarity_users, kind='user')\n",
    "f1_matrix(R_train, R_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_predicted = predict(R_train, similarity_items, kind='item')\n",
    "f1_matrix(R_train, R_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the similarity of users and items using the features datasets rather than the attempt_ranges themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_norm = users.set_index('user_id')/users.set_index('user_id').max()\n",
    "user_features_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_predicted = predict(R_train, cos_sim(user_features_norm))\n",
    "f1_matrix(R_train, R_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_features_norm = problems.set_index('problem_id')/problems.set_index('problem_id').max()\n",
    "problem_features_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_predicted = predict(R_train, cos_sim(problem_features_norm), kind='item')\n",
    "f1_matrix(R_train, R_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of model is by far the worst for this particular dataset..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Factor Collaborative Filtering Model From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the really fun part! I'm going to build a collaborative filtering model from scratch. In this type of model, latent features will be learned from the user-problem submission history. No data will be used from the users and problems datasets. We will define how many latent features we want the model to train on, this is a hyperparameter that we can tune later on. We will start by initializing a random guess of these latent features and then train the model by minimizing the error the model produces when predicting the attempts_ranges for user-problem combinations, from the learned latent features. To minimize the cost or error, J, we will utilize stochastic gradient descent. I'll start by defining some useful functions to help build the pipeline for the model. Keep in mind that we're starting with a single matrix with users on the row index and items (in this case problems) on the column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_10</th>\n",
       "      <th>prob_100</th>\n",
       "      <th>prob_1000</th>\n",
       "      <th>prob_1001</th>\n",
       "      <th>prob_1002</th>\n",
       "      <th>prob_1003</th>\n",
       "      <th>prob_1004</th>\n",
       "      <th>prob_1005</th>\n",
       "      <th>prob_1006</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_990</th>\n",
       "      <th>prob_991</th>\n",
       "      <th>prob_992</th>\n",
       "      <th>prob_993</th>\n",
       "      <th>prob_994</th>\n",
       "      <th>prob_995</th>\n",
       "      <th>prob_996</th>\n",
       "      <th>prob_997</th>\n",
       "      <th>prob_998</th>\n",
       "      <th>prob_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           prob_1  prob_10  prob_100  prob_1000  prob_1001  prob_1002  \\\n",
       "user_1        NaN      NaN       NaN        NaN        NaN        NaN   \n",
       "user_10       NaN      NaN       NaN        NaN        NaN        NaN   \n",
       "user_100      NaN      NaN       NaN        NaN        NaN        NaN   \n",
       "user_1000     NaN      NaN       NaN        1.0        NaN        NaN   \n",
       "user_1001     NaN      NaN       NaN        NaN        NaN        NaN   \n",
       "\n",
       "           prob_1003  prob_1004  prob_1005  prob_1006  ...  prob_990  \\\n",
       "user_1           NaN        NaN        NaN        NaN  ...       NaN   \n",
       "user_10          NaN        NaN        NaN        NaN  ...       NaN   \n",
       "user_100         NaN        NaN        NaN        NaN  ...       NaN   \n",
       "user_1000        NaN        NaN        NaN        NaN  ...       NaN   \n",
       "user_1001        NaN        NaN        NaN        NaN  ...       NaN   \n",
       "\n",
       "           prob_991  prob_992  prob_993  prob_994  prob_995  prob_996  \\\n",
       "user_1          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_10         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_100        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_1000       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "user_1001       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "           prob_997  prob_998  prob_999  \n",
       "user_1          NaN       NaN       NaN  \n",
       "user_10         NaN       NaN       NaN  \n",
       "user_100        NaN       NaN       NaN  \n",
       "user_1000       NaN       NaN       NaN  \n",
       "user_1001       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 6544 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function takes two matrices and flattens them into a single 1D array. It does so by first sequentially stacking each column on top of each other for each matrix, producing two 1D arrays. It then stacks those two 1D arrays on top of each other to form a single 1D array that contains all of the latent features for users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll(M_users, M_items):\n",
    "    \n",
    "    \"\"\"Reshape 2 matrices into a single 1D array. \n",
    "    Inverse function of `roll`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    M_users : 2D numpy array\n",
    "        Matrix of user latent features. Has\n",
    "        dimensions (n_users, n_features).\n",
    "    M_items : 2D numpy array\n",
    "        Matrix of item latent features. Has\n",
    "        dimensions (n_items, n_features).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x_users_items : 1D numpy array\n",
    "        User and item latent features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert matrices to np arrays\n",
    "    M_users = np.array(M_users)\n",
    "    M_items = np.array(M_items)\n",
    "\n",
    "    # flatten 2D arrays into 1D arrays\n",
    "    x_users = M_users.flatten(order='C')\n",
    "    x_items = M_items.flatten(order='C')\n",
    "    \n",
    "    # concatenate user and item 1D arrays\n",
    "    x_users_items = np.concatenate((x_users, x_items), axis=0)\n",
    "\n",
    "    return x_users_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011500\n",
      "(1011500,)\n",
      "Wall time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_users = R_train.shape[0]\n",
    "n_items = R_train.shape[1]\n",
    "n_features = 100\n",
    "\n",
    "M_users = np.random.rand(n_users, n_features)\n",
    "M_items = np.random.rand(n_items, n_features)\n",
    "\n",
    "x_users_items = unroll(M_users, M_items)\n",
    "\n",
    "print(n_users*n_features + n_items*n_features)\n",
    "print(x_users_items.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is quite fast, taking only 20 ms to generate two random matrices and pass them into unroll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### roll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function does the inverse of unroll. It takes a single 1D array of user and item latent features and reshapes them into their original matrix forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(x_users_items, n_users, n_items, n_features):\n",
    "    \n",
    "    \"\"\"Reshape a 1D array of user and item latent\n",
    "    features into their original 2D array format.\n",
    "    Inverse function of `unroll`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_users_items : 1D numpy array\n",
    "        User and item latent features.\n",
    "    n_users : int\n",
    "        Number of users.\n",
    "    n_items : int\n",
    "        Number of items.\n",
    "    n_features: int\n",
    "        Number of latent features to learn. \n",
    "        Determines the overall size of M_users \n",
    "        and M_items.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    M_users : 2D numpy array\n",
    "        Matrix of user latent features. Has\n",
    "        dimensions (n_users, n_features).\n",
    "    M_items : 2D numpy array\n",
    "        Matrix of item latent features. Has\n",
    "        dimensions (n_items, n_features).\n",
    "    \"\"\"\n",
    "    \n",
    "    # retrieve user and item 1D arrays\n",
    "    x_users = x_users_items[0:n_users*n_features]\n",
    "    x_items = x_users_items[n_users*n_features:]\n",
    "    \n",
    "    # reshape 1D arrays into original matrices\n",
    "    M_users = np.reshape(x_users, (n_users, n_features))\n",
    "    M_items = np.reshape(x_items, (n_items, n_features))\n",
    "\n",
    "    return M_users, M_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3571, 100) (6544, 100)\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_users = R_train.shape[0]\n",
    "n_items = R_train.shape[1]\n",
    "n_features = 100\n",
    "\n",
    "M_users, M_items = roll(x_users_items, n_users, n_items, n_features)\n",
    "print(M_users.shape, M_items.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is also quite fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function compute the cost or error, J, for a prediction made using the values in x_users_items, against the true values in Y_true. The cost is calculated as the sum of squared errors plus a regularization penatly for both user and item 2nd order latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x_users_items, Y_true, Lambda, n_users, n_items, n_features):\n",
    "    \n",
    "    \"\"\"Compute cost (error) J from predictions on \n",
    "    Y_true using learned features `x_users_items`. J \n",
    "    is defined as the sum of squared errors plus\n",
    "    regularization penatlies on user and item \n",
    "    latent features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_users_items : 1D numpy array\n",
    "        User and item latent features.\n",
    "    Y_true : 2D numpy array\n",
    "        Matrix containing true ratings.\n",
    "    Lambda : int\n",
    "        Regularization coefficient.\n",
    "    n_users : int\n",
    "        Number of users.\n",
    "    n_items : int\n",
    "        Number of items.\n",
    "    n_features: int\n",
    "        Number of latent features to learn. \n",
    "        Determines the overall size of M_users \n",
    "        and M_items.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        Cost associated with prediction on `Y_true` \n",
    "        using learned latent features `x_users_items`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # recover 2D user and item feature matrices\n",
    "    M_users, M_items = roll(x_users_items, n_users, n_items, n_features)\n",
    "\n",
    "    # compute the prediction\n",
    "    Y_predicted = np.dot(M_users, M_items.T)\n",
    "    \n",
    "    # compute the error in the prediction\n",
    "    error = Y_true - Y_predicted\n",
    "    # replace all NaN values with 0\n",
    "    error[np.isnan(error)] = 0\n",
    "\n",
    "    # compute the regularization penalties\n",
    "    User_regularization = (Lambda/2) * np.nansum(M_users * M_users)\n",
    "    Item_regularization = (Lambda/2) * np.nansum(M_items * M_items)\n",
    "\n",
    "    # compute the cost J with regularization\n",
    "    J = (1/2) * np.nansum(error*error) + User_regularization + Item_regularization\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23838459.908534266\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_users = R_train.shape[0]\n",
    "n_items = R_train.shape[1]\n",
    "n_features = 100\n",
    "Lambda=0.1 # regularization coefficient\n",
    "\n",
    "J = cost(x_users_items, R_train, Lambda, n_users, n_items, n_features)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the cost takes a bit longer at 1 second. We can see the very large cost J for our initial random guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name suggests, this function computes the gradient of the cost function, evaluated independently for the user and item latent features. The gradient is what we use to decide in which direction to step in during each update or iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x_users_items, Y_true, Lambda, n_users, n_items, n_features):\n",
    "    \n",
    "    \"\"\"Compute gradient function on `x_users_items`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_users_items : 1D numpy array\n",
    "        User and item latent features.\n",
    "    Y_true : 2D numpy array\n",
    "        Matrix containing true ratings.\n",
    "    Lambda : int\n",
    "        Regularization coefficient.\n",
    "    n_users : int\n",
    "        Number of users.\n",
    "    n_items : int\n",
    "        Number of items.\n",
    "    n_features: int\n",
    "        Number of latent features to learn. \n",
    "        Determines the overall size of M_users \n",
    "        and M_items.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    gradient : 1D numpy array\n",
    "        Gradient of cost J w.r.t user and item\n",
    "        latent features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # recover 2D user and item feature matrices\n",
    "    M_users, M_items = roll(x_users_items, n_users, n_items, n_features)\n",
    "\n",
    "    # compute the prediction\n",
    "    Y_predicted = np.dot(M_users, M_items.T)\n",
    "    \n",
    "    # compute the error in the prediction\n",
    "    error = Y_true - Y_predicted\n",
    "    # replace all NaN values with 0\n",
    "    error[np.isnan(error)] = 0 \n",
    "\n",
    "    # the gradients of user & item features\n",
    "    M_user_gradient = np.dot(error, M_items) + Lambda*M_users\n",
    "    M_item_gradient = np.dot(error.T, M_users) + Lambda*M_items\n",
    "\n",
    "    # reshape gradients into 1D array\n",
    "    gradient = unroll(M_user_gradient, M_item_gradient)\n",
    "\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3.64724205e+02, -4.85851599e+02, -4.66740767e+02, ...,\n",
       "       -4.43565122e-01, -8.28989529e+00, -7.97167493e+00])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_users = R_train.shape[0]\n",
    "n_items = R_train.shape[1]\n",
    "n_features = 100\n",
    "Lambda=0.1 # regularization coefficient\n",
    "\n",
    "grad = gradient(x_users_items, R_train, Lambda, n_users, n_items, n_features)\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also takes close to 1 second to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name implies, this function takes in the trained latent features in x_users_items and computes the predicted attempts_range from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_users_items, n_users, n_items, n_features):\n",
    "    \n",
    "    \"\"\"Compute prediction on ratings. Predictions\n",
    "    are computed from learned user and item \n",
    "    latent features in `x_users_items`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_users_items : 1D numpy array\n",
    "        User and item latent features.\n",
    "    n_users : int\n",
    "        Number of users.\n",
    "    n_items : int\n",
    "        Number of items.\n",
    "    n_features: int\n",
    "        Number of latent features to learn. \n",
    "        Determines the overall size of M_users \n",
    "        and M_items.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    Y_predicted : pandas DataFrame\n",
    "        Predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # recover 2D user and item feature matrices\n",
    "    M_users, M_items = roll(x_users_items, n_users, n_items, n_features)\n",
    "\n",
    "    # compute predictions from P & Q\n",
    "    Y_predicted = np.dot(M_users, M_items.T) \n",
    "    \n",
    "    # set all negative predictions to 1 (bottom limit)\n",
    "    Y_predicted[Y_predicted < 1] = 1\n",
    "    \n",
    "    Y_predicted = Y_predicted.astype(int)\n",
    "    \n",
    "    return Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 282 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29, 22, 28, ..., 24, 29, 26],\n",
       "       [27, 24, 27, ..., 24, 29, 26],\n",
       "       [27, 22, 28, ..., 23, 29, 26],\n",
       "       ...,\n",
       "       [28, 25, 26, ..., 24, 29, 27],\n",
       "       [26, 22, 25, ..., 22, 27, 23],\n",
       "       [26, 22, 24, ..., 21, 25, 25]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_users = R_train.shape[0]\n",
    "n_items = R_train.shape[1]\n",
    "n_features = 100\n",
    "\n",
    "predict(x_users_items, n_users, n_items, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction step only takes 262 ms. We can see the predicted values are no where even close to what the attempts_ranges should be. Of course, the initial prediction is expected to be way off since we just randomly initialized the latent feature values. We will see how these numbers evolve as we train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the meat of the training algorithm. SGD stands for stochastic gradient descent. It's an iterative agorithm that computes the error using a cost function J which we defined above, and steps in the direction (given by the gradient) that will minimize J in the next step. The latent feature values x_users_items are updated at each step until a convergence criteria is met. In this case, the e in SGD_e stands for epoch. This implementation will execute for a fixed number of epochs. Let's go ahead and take it for a spin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_e(R_train, n_users, n_items, n_features, Lambda, \n",
    "          epochs, alpha, compute_f1=False, seed=42, **kwargs):\n",
    "    \n",
    "    \"\"\"Stochastic gradient descent algorithm. Searches\n",
    "    for the optimal values of user and item latent\n",
    "    features in x_users_items, that minimize the cost J.\n",
    "    Updates are calculated for `epochs` iterations using a \n",
    "    learning rate `alpha`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    R_train : 2D numpy array\n",
    "        Ratings matrix for training dataset.\n",
    "    R_cv : 2D numpy array\n",
    "        Ratings matrix for cross-validation dataset.\n",
    "    n_users : int\n",
    "        Number of users.\n",
    "    n_items : int\n",
    "        Number of items.\n",
    "    n_features: int\n",
    "        Number of latent features to learn. \n",
    "        Determines the overall size of M_users \n",
    "        and M_items.\n",
    "    Lambda : int\n",
    "        Regularization coefficient.\n",
    "    epochs : int\n",
    "        Number of iterations to run.\n",
    "    alpha : float\n",
    "        Learning rate.\n",
    "    compute_f1 : bool (default False)\n",
    "        If true, computes the f1-scores for predictions\n",
    "        on R_train and R_cv at each epoch.\n",
    "    seed : int (default 42)\n",
    "        Seed for numpy's pseudo-random number\n",
    "        generator.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        Nested dictionary containing epoch as keys. Values\n",
    "        associated with each `epochs` are cost J, f1-scores \n",
    "        for training and CV datasets, and optimized \n",
    "        parameters `x_users_items`.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # get cross-validation data if given\n",
    "    R_cv = kwargs.get('R_cv')\n",
    "    \n",
    "    # set random seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # intial random guess of user and item\n",
    "    # latent features\n",
    "    M_users = np.random.rand(n_users, n_features) - 0.5\n",
    "    M_items = np.random.rand(n_items, n_features) - 0.5\n",
    "    \n",
    "    # reshape matrices into 1D array of\n",
    "    # user and item latent features\n",
    "    x_users_items = unroll(M_users, M_items)\n",
    "    \n",
    "    # initialize empty dict to store training results\n",
    "    results = {}\n",
    "    \n",
    "    # loop through `epochs` iterations\n",
    "    for e in range(1,epochs+1):\n",
    "        \n",
    "        # compute the cost\n",
    "        J = cost(x_users_items, R_train, Lambda, \n",
    "                   n_users, n_items, n_features)\n",
    "        \n",
    "        # compute the gradient function\n",
    "        gradient_ = gradient(x_users_items, R_train, Lambda, \n",
    "                      n_users, n_items, n_features)\n",
    "        \n",
    "        # update `x_users_items`\n",
    "        x_users_items = x_users_items + alpha * gradient_\n",
    "        \n",
    "        if compute_f1:\n",
    "            # make prediction\n",
    "            Y_predicted = predict(x_users_items, n_users, n_items, n_features)\n",
    "\n",
    "            # store cost J, f1-scores on training and CV data,\n",
    "            # and the optimized parameters `x_users_items`.\n",
    "            results[e] = {'J': J, 'f1-train': f1_matrix(R_train, Y_predicted), \n",
    "                          'f1-cv': f1_matrix(R_cv, Y_predicted), 'x_users_items': x_users_items}\n",
    "            \n",
    "        else:\n",
    "            # store cost J and optimized parameters `x_users_items`\n",
    "            results[e] = {'J': J, 'x_users_items': x_users_items}\n",
    "        \n",
    "        # print current epoch and cost\n",
    "        print('Epoch %s' % e + ' | ' + 'J : %s' % round(J))\n",
    "        \n",
    "        # logic for stop condition\n",
    "        if e > 1:\n",
    "            # compute delta for current iteration\n",
    "            delta = (results[e-1]['J'] - results[e]['J'])\n",
    "            \n",
    "            # if J increases from last iteration (delta < 0)\n",
    "            # end updates and return results\n",
    "            if delta < 0:\n",
    "                print('Gradient diverging! Ending training...')\n",
    "                return results\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # indicate completion and print final J\n",
    "    print('Training complete, final J: %s' % round(results[epochs]['J']))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | J : 187802.0\n",
      "Epoch 2 | J : 181496.0\n",
      "delta: 6305.159405808954\n",
      "Epoch 3 | J : 175672.0\n",
      "delta: 5824.303110547073\n",
      "Epoch 4 | J : 167338.0\n",
      "delta: 8334.293891633191\n",
      "Epoch 5 | J : 151792.0\n",
      "delta: 15545.914596866089\n",
      "Epoch 6 | J : 124942.0\n",
      "delta: 26850.409929636604\n",
      "Epoch 7 | J : 96935.0\n",
      "delta: 28006.609274381073\n",
      "Epoch 8 | J : 76578.0\n",
      "delta: 20356.440915378058\n",
      "Epoch 9 | J : 64031.0\n",
      "delta: 12547.92035841605\n",
      "Epoch 10 | J : 63986.0\n",
      "delta: 44.15742871346447\n",
      "Epoch 11 | J : 126637.0\n",
      "delta: -62650.6762465129\n",
      "Gradient diverging! Ending training...\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# data parameters\n",
    "n_users = R_train_.shape[0]\n",
    "n_items = R_train_.shape[1]\n",
    "\n",
    "# hyper parameters\n",
    "n_features = 10\n",
    "Lambda=0.01\n",
    "epochs=20\n",
    "alpha=0.01\n",
    "\n",
    "results = SGD_e(R_train_, n_users, n_items, n_features, Lambda, \n",
    "                epochs, alpha, compute_f1=True, seed=42, R_cv=R_cv_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "type": "scattergl",
         "uid": "5f70ea18-ad19-11e9-af3c-e442a6f8adc6",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
         ],
         "y": [
          187801.59524029645,
          181496.4358344875,
          175672.13272394042,
          167337.83883230723,
          151791.92423544114,
          124941.51430580454,
          96934.90503142346,
          76578.4641160454,
          64030.543757629355,
          63986.38632891589,
          126637.06257542879
         ]
        }
       ],
       "layout": {
        "title": "Cost Function vs epoch",
        "xaxis": {
         "title": "epoch"
        },
        "yaxis": {
         "title": "Cost Function",
         "type": "log"
        }
       }
      },
      "text/html": [
       "<div id=\"5a67822b-cf9c-473b-a281-93ce1f508364\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '5a67822b-cf9c-473b-a281-93ce1f508364',\n",
       "            [{\"mode\": \"lines+markers\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0], \"y\": [187801.59524029645, 181496.4358344875, 175672.13272394042, 167337.83883230723, 151791.92423544114, 124941.51430580454, 96934.90503142346, 76578.4641160454, 64030.543757629355, 63986.38632891589, 126637.06257542879], \"type\": \"scattergl\", \"uid\": \"5f70ea18-ad19-11e9-af3c-e442a6f8adc6\"}],\n",
       "            {\"title\": \"Cost Function vs epoch\", \"xaxis\": {\"title\": \"epoch\"}, \"yaxis\": {\"title\": \"Cost Function\", \"type\": \"log\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('5a67822b-cf9c-473b-a281-93ce1f508364',{});}).then(function(){Plotly.animate('5a67822b-cf9c-473b-a281-93ce1f508364');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"5a67822b-cf9c-473b-a281-93ce1f508364\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '5a67822b-cf9c-473b-a281-93ce1f508364',\n",
       "            [{\"mode\": \"lines+markers\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0], \"y\": [187801.59524029645, 181496.4358344875, 175672.13272394042, 167337.83883230723, 151791.92423544114, 124941.51430580454, 96934.90503142346, 76578.4641160454, 64030.543757629355, 63986.38632891589, 126637.06257542879], \"type\": \"scattergl\", \"uid\": \"5f70ea18-ad19-11e9-af3c-e442a6f8adc6\"}],\n",
       "            {\"title\": \"Cost Function vs epoch\", \"xaxis\": {\"title\": \"epoch\"}, \"yaxis\": {\"title\": \"Cost Function\", \"type\": \"log\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('5a67822b-cf9c-473b-a281-93ce1f508364',{});}).then(function(){Plotly.animate('5a67822b-cf9c-473b-a281-93ce1f508364');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array(list(results.keys()))\n",
    "y = np.array([results[i]['J'] for i in results.keys()])\n",
    "\n",
    "trace0=go.Scattergl(x=x, y=y, mode='lines+markers')\n",
    "\n",
    "layout=go.Layout(title='Cost Function vs epoch',\n",
    "                yaxis=dict(title='Cost Function',\n",
    "                          type='log'),\n",
    "                xaxis=dict(title='epoch'))\n",
    "\n",
    "fig = go.Figure([trace0], layout)\n",
    "\n",
    "iplot(fig, filename='training.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J': 63986.38632891589,\n",
       " 'f1-train': 0.493357831544373,\n",
       " 'f1-cv': 0.4379398584326611,\n",
       " 'x_users_items': array([ 0.16602717, -0.32074901,  0.40938191, ...,  0.10771847,\n",
       "        -0.26563553,  0.28468026])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(results[10]['x_users_items'], n_users, n_items, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "results_100epochs = load_obj('initial_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines+markers",
         "type": "scattergl",
         "uid": "22fbf79a-ad1a-11e9-b5a7-e442a6f8adc6",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "y": [
          188410.2922533717,
          187719.73446866721,
          187053.95143800965,
          186409.23458398975,
          185782.27903924094,
          185170.10543596177,
          184569.99614345166,
          183979.4425406271,
          183396.10075009827,
          182817.7538713838,
          182242.27920170722,
          181667.61927046784,
          181091.7557707759,
          180512.68567180345,
          179928.3989564791,
          179336.85756309162,
          178735.97522677202,
          178123.5980257642,
          177497.48554427637,
          176855.29267420096,
          176194.5521963051,
          175512.65841085493,
          174806.85222972083,
          174074.20829620105,
          173311.62486204458,
          172515.81731628306,
          171683.3164160774,
          170810.47239886865,
          169893.46623503827,
          168928.32928338784,
          167910.97250670614,
          166837.22616112846,
          165702.89046620592,
          164503.79718287446,
          163235.88128751007,
          161895.2610792427,
          160478.32418124276,
          158981.8161209352,
          157402.927654005,
          155739.37689374085,
          153989.48275162274,
          152152.22724435394,
          150227.30581636156,
          148215.16675738455,
          146117.04270489825,
          143934.97864164034,
          141671.86123165092,
          139331.45337870443,
          136918.43536522932,
          134438.4500163082,
          131898.1446218884,
          129305.19779888274,
          126668.31624822291,
          123997.18556849842,
          121302.36167376357,
          118595.0950489373,
          115887.08842466632,
          113190.19812613438,
          110516.0985599076,
          107875.93620672745,
          105280.00262411279,
          102737.45461249995,
          100256.10407616106,
          97842.29131714912,
          95500.84525341984,
          93235.12425268973,
          91047.12354858528,
          88937.63055595299,
          86906.40805810226,
          84952.38674275807,
          83073.8520187013,
          81268.61442058765,
          79534.15729926019,
          77867.75926928068,
          76266.59172684335,
          74727.79360582045,
          73248.52652805623,
          71826.01383085757,
          70457.56683831276,
          69140.60137351479,
          67872.64702925221,
          66651.35122070546,
          65474.47959045303,
          64339.91394946538,
          63245.64862434539,
          62189.785836553114,
          61170.53055410928,
          60186.18511921343,
          59235.14385572938,
          58315.88778940623,
          57426.97956360853,
          56567.05859851925,
          55734.83651786591,
          54929.09285113333,
          54148.67100862962,
          53392.47452003072,
          52659.46352302382,
          51948.65148651844,
          51259.102152056264,
          50589.926677060714
         ]
        }
       ],
       "layout": {
        "title": "Cost Function vs epoch",
        "xaxis": {
         "title": "epoch"
        },
        "yaxis": {
         "title": "Cost Function",
         "type": "log"
        }
       }
      },
      "text/html": [
       "<div id=\"0c99d0e8-5d8e-41ea-b12e-a14e701ec775\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '0c99d0e8-5d8e-41ea-b12e-a14e701ec775',\n",
       "            [{\"mode\": \"lines+markers\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"y\": [188410.2922533717, 187719.73446866721, 187053.95143800965, 186409.23458398975, 185782.27903924094, 185170.10543596177, 184569.99614345166, 183979.4425406271, 183396.10075009827, 182817.7538713838, 182242.27920170722, 181667.61927046784, 181091.7557707759, 180512.68567180345, 179928.3989564791, 179336.85756309162, 178735.97522677202, 178123.5980257642, 177497.48554427637, 176855.29267420096, 176194.5521963051, 175512.65841085493, 174806.85222972083, 174074.20829620105, 173311.62486204458, 172515.81731628306, 171683.3164160774, 170810.47239886865, 169893.46623503827, 168928.32928338784, 167910.97250670614, 166837.22616112846, 165702.89046620592, 164503.79718287446, 163235.88128751007, 161895.2610792427, 160478.32418124276, 158981.8161209352, 157402.927654005, 155739.37689374085, 153989.48275162274, 152152.22724435394, 150227.30581636156, 148215.16675738455, 146117.04270489825, 143934.97864164034, 141671.86123165092, 139331.45337870443, 136918.43536522932, 134438.4500163082, 131898.1446218884, 129305.19779888274, 126668.31624822291, 123997.18556849842, 121302.36167376357, 118595.0950489373, 115887.08842466632, 113190.19812613438, 110516.0985599076, 107875.93620672745, 105280.00262411279, 102737.45461249995, 100256.10407616106, 97842.29131714912, 95500.84525341984, 93235.12425268973, 91047.12354858528, 88937.63055595299, 86906.40805810226, 84952.38674275807, 83073.8520187013, 81268.61442058765, 79534.15729926019, 77867.75926928068, 76266.59172684335, 74727.79360582045, 73248.52652805623, 71826.01383085757, 70457.56683831276, 69140.60137351479, 67872.64702925221, 66651.35122070546, 65474.47959045303, 64339.91394946538, 63245.64862434539, 62189.785836553114, 61170.53055410928, 60186.18511921343, 59235.14385572938, 58315.88778940623, 57426.97956360853, 56567.05859851925, 55734.83651786591, 54929.09285113333, 54148.67100862962, 53392.47452003072, 52659.46352302382, 51948.65148651844, 51259.102152056264, 50589.926677060714], \"type\": \"scattergl\", \"uid\": \"22fbf79a-ad1a-11e9-b5a7-e442a6f8adc6\"}],\n",
       "            {\"title\": \"Cost Function vs epoch\", \"xaxis\": {\"title\": \"epoch\"}, \"yaxis\": {\"title\": \"Cost Function\", \"type\": \"log\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('0c99d0e8-5d8e-41ea-b12e-a14e701ec775',{});}).then(function(){Plotly.animate('0c99d0e8-5d8e-41ea-b12e-a14e701ec775');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"0c99d0e8-5d8e-41ea-b12e-a14e701ec775\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '0c99d0e8-5d8e-41ea-b12e-a14e701ec775',\n",
       "            [{\"mode\": \"lines+markers\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"y\": [188410.2922533717, 187719.73446866721, 187053.95143800965, 186409.23458398975, 185782.27903924094, 185170.10543596177, 184569.99614345166, 183979.4425406271, 183396.10075009827, 182817.7538713838, 182242.27920170722, 181667.61927046784, 181091.7557707759, 180512.68567180345, 179928.3989564791, 179336.85756309162, 178735.97522677202, 178123.5980257642, 177497.48554427637, 176855.29267420096, 176194.5521963051, 175512.65841085493, 174806.85222972083, 174074.20829620105, 173311.62486204458, 172515.81731628306, 171683.3164160774, 170810.47239886865, 169893.46623503827, 168928.32928338784, 167910.97250670614, 166837.22616112846, 165702.89046620592, 164503.79718287446, 163235.88128751007, 161895.2610792427, 160478.32418124276, 158981.8161209352, 157402.927654005, 155739.37689374085, 153989.48275162274, 152152.22724435394, 150227.30581636156, 148215.16675738455, 146117.04270489825, 143934.97864164034, 141671.86123165092, 139331.45337870443, 136918.43536522932, 134438.4500163082, 131898.1446218884, 129305.19779888274, 126668.31624822291, 123997.18556849842, 121302.36167376357, 118595.0950489373, 115887.08842466632, 113190.19812613438, 110516.0985599076, 107875.93620672745, 105280.00262411279, 102737.45461249995, 100256.10407616106, 97842.29131714912, 95500.84525341984, 93235.12425268973, 91047.12354858528, 88937.63055595299, 86906.40805810226, 84952.38674275807, 83073.8520187013, 81268.61442058765, 79534.15729926019, 77867.75926928068, 76266.59172684335, 74727.79360582045, 73248.52652805623, 71826.01383085757, 70457.56683831276, 69140.60137351479, 67872.64702925221, 66651.35122070546, 65474.47959045303, 64339.91394946538, 63245.64862434539, 62189.785836553114, 61170.53055410928, 60186.18511921343, 59235.14385572938, 58315.88778940623, 57426.97956360853, 56567.05859851925, 55734.83651786591, 54929.09285113333, 54148.67100862962, 53392.47452003072, 52659.46352302382, 51948.65148651844, 51259.102152056264, 50589.926677060714], \"type\": \"scattergl\", \"uid\": \"22fbf79a-ad1a-11e9-b5a7-e442a6f8adc6\"}],\n",
       "            {\"title\": \"Cost Function vs epoch\", \"xaxis\": {\"title\": \"epoch\"}, \"yaxis\": {\"title\": \"Cost Function\", \"type\": \"log\"}},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('0c99d0e8-5d8e-41ea-b12e-a14e701ec775',{});}).then(function(){Plotly.animate('0c99d0e8-5d8e-41ea-b12e-a14e701ec775');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array(list(results_100epochs.keys()))\n",
    "y = np.array([results_100epochs[i]['J'] for i in results_100epochs.keys()])\n",
    "\n",
    "trace0=go.Scattergl(x=x, y=y, mode='lines+markers')\n",
    "\n",
    "layout=go.Layout(title='Cost Function vs epoch',\n",
    "                yaxis=dict(title='Cost Function',\n",
    "                          type='log'),\n",
    "                xaxis=dict(title='epoch'))\n",
    "\n",
    "fig = go.Figure([trace0], layout)\n",
    "\n",
    "iplot(fig, filename='training.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J': 50589.926677060714,\n",
       " 'F1-train': 0.5178311985749524,\n",
       " 'F1-cv': 0.4516169439596815,\n",
       " 'xopt': array([ 0.1384063 , -0.11193197, -0.01139779, ..., -0.83185053,\n",
       "         0.50665992, -0.281704  ])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_100epochs[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_t(R_train, n_users, n_items, n_features, Lambda, \n",
    "          epsilon, alpha, compute_f1=False, seed=42, **kwargs):\n",
    "    \n",
    "    \"\"\"Stochastic gradient descent algorithm. Searches\n",
    "    for the optimal values of user and item latent\n",
    "    features in x_users_items, that minimize the cost J.\n",
    "    Updates are calculated until the change (delta) in J, \n",
    "    between iterations, is less than epsilon.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    R_train : 2D numpy array\n",
    "        Ratings matrix for training dataset.\n",
    "    R_cv : 2D numpy array (optional, must be given if\n",
    "    `compute_f1` is True)\n",
    "        Ratings matrix for cross-validation dataset.\n",
    "    n_users : int\n",
    "        Number of users.\n",
    "    n_items : int\n",
    "        Number of items.\n",
    "    n_features: int\n",
    "        Number of latent features to learn. \n",
    "        Determines the overall size of M_users \n",
    "        and M_items.\n",
    "    Lambda : int\n",
    "        Regularization coefficient.\n",
    "    epsilon : float\n",
    "        Training threshold. Training stops when the cost\n",
    "        J is less than epsilon.\n",
    "    alpha : float\n",
    "        Learning rate.\n",
    "    compute_f1 : bool (default False)\n",
    "        If true, computes the f1-scores for predictions\n",
    "        on R_train and R_cv at each epoch.\n",
    "    seed : int (default 42)\n",
    "        Seed for numpy's pseudo-random number\n",
    "        generator.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        Nested dictionary containing epoch as keys. Values\n",
    "        associated with each `epochs` are cost J, f1-scores \n",
    "        for training and CV datasets, and optimized \n",
    "        parameters `x_users_items`.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # get cross-validation data if given\n",
    "    R_cv = kwargs.get('R_cv')\n",
    "    \n",
    "    # set random seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # intial random guess of user and item\n",
    "    # latent features\n",
    "    M_users = np.random.rand(n_users, n_features) - 0.5\n",
    "    M_items = np.random.rand(n_items, n_features) - 0.5\n",
    "    \n",
    "    # reshape matrices into 1D array of\n",
    "    # user and item latent features\n",
    "    x_users_items = unroll(M_users, M_items)\n",
    "    \n",
    "    # initialize empty dict to store training results\n",
    "    results = {}\n",
    "    \n",
    "    e = 1 # counter for training iteration\n",
    "    \n",
    "    # large, arbitrary initial value for delta in J\n",
    "    delta = 1000\n",
    "    \n",
    "    # iterate until the delta in J is less than epsilon\n",
    "    while delta > epsilon:\n",
    "        \n",
    "        # compute the cost\n",
    "        J = cost(x_users_items, R_train, Lambda, \n",
    "                   n_users, n_items, n_features)\n",
    "        \n",
    "        # compute the gradient function\n",
    "        gradient_ = gradient(x_users_items, R_train, Lambda, \n",
    "                      n_users, n_items, n_features)\n",
    "        \n",
    "        # update `x_users_items`\n",
    "        x_users_items = x_users_items + alpha * gradient_\n",
    "        \n",
    "        if compute_f1:\n",
    "            # make prediction\n",
    "            Y_predicted = predict(x_users_items, n_users, n_items, n_features)\n",
    "\n",
    "            # store cost J, f1-scores on training and CV data,\n",
    "            # and the optimized parameters `x_users_items`.\n",
    "            results[e] = {'J': J, 'f1-train': f1_matrix(R_train, Y_predicted), \n",
    "                          'f1-cv': f1_matrix(R_cv, Y_predicted), 'x_users_items': x_users_items}\n",
    "            \n",
    "        else:\n",
    "            # store cost J and optimized parameters `x_users_items`\n",
    "            results[e] = {'J': J, 'x_users_items': x_users_items}\n",
    "        \n",
    "        # print current epoch and cost\n",
    "        print('Epoch %s' % e + ' | ' + 'J : %s' % round(J))\n",
    "        \n",
    "        # logic for stop condition\n",
    "        if e > 1:\n",
    "            # compute delta for current iteration\n",
    "            delta = (results[e-1]['J'] - results[e]['J'])\n",
    "            \n",
    "            # if J increases from last iteration (delta < 0)\n",
    "            # end updates and return results\n",
    "            if delta < 0:\n",
    "                print('Gradient diverging! Ending training...')\n",
    "                return results\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        print('Cost delta: %s' % round(delta))\n",
    "        print()\n",
    "        \n",
    "        e += 1\n",
    "    \n",
    "    # indicate completion and print final J\n",
    "    print('Stopping criteria met: delta < epsilon.')\n",
    "    print('Final J: %s' % round(results[epochs]['J']))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
